{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a9f987",
   "metadata": {},
   "source": [
    "### 텐서의 랭크와 크기를 확인하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d3658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301d8ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## t1, t2, t3 텐서를 정의\n",
    "t1 = tf.constant(np.pi)\n",
    "t2 = tf.constant([1,2,3,4])\n",
    "t3 = tf.constant([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee588a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#랭크를 구함\n",
    "r1 = tf.rank(t1)\n",
    "r2 = tf.rank(t2)\n",
    "r3 = tf.rank(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebdbac77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크기: () (4,) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "#크기를 구함\n",
    "s1 = t1.get_shape()\n",
    "s2 = t2.get_shape()\n",
    "s3 = t3.get_shape()\n",
    "print(\"크기:\",s1,s2,s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02e8312b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랭크: 0 1 2\n"
     ]
    }
   ],
   "source": [
    "print(\"랭크:\",r1.numpy(),r2.numpy(),r3.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0ff7fc",
   "metadata": {},
   "source": [
    "### 텐서를 다차원 배열로 변환 tf.constant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fd11bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1.,2.,3.,3.5],\n",
    "                [4.,5.,6.,6.5],\n",
    "               [7.,8.,9.,9.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ea6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = tf.constant(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c2c77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.  2.  3.  3.5]\n",
      " [4.  5.  6.  6.5]\n",
      " [7.  8.  9.  9.5]], shape=(3, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95a2d629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  2.  3.  3.5]\n",
      " [4.  5.  6.  6.5]\n",
      " [7.  8.  9.  9.5]]\n"
     ]
    }
   ],
   "source": [
    "print(T1.numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a7d1e2",
   "metadata": {},
   "source": [
    "### 형태 .get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a318639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_shape(): TensorShape객체 반환\n",
    "s = T1.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cfc0d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1의 크기: (3, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"T1의 크기:\",s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c319643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1의 크기: (3, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"T1의 크기:\",T1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2157cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "T2 = tf.Variable(np.random.normal(size = s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a4062ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float64, numpy=\n",
      "array([[ 1.05256319,  0.23730106,  1.20871267,  0.11732484],\n",
      "       [ 1.00040741,  0.93953975,  0.36014743,  1.546689  ],\n",
      "       [ 1.08038816, -0.79511305,  0.57646042,  0.1497009 ]])>\n"
     ]
    }
   ],
   "source": [
    "print(T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e71204ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.05256319  0.23730106  1.20871267  0.11732484]\n",
      " [ 1.00040741  0.93953975  0.36014743  1.546689  ]\n",
      " [ 1.08038816 -0.79511305  0.57646042  0.1497009 ]]\n"
     ]
    }
   ],
   "source": [
    "print(T2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "918ea39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "T3 = tf.Variable(np.random.normal(size = s[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7350ef8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.20975673, -0.70145509,  0.9807294 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T3.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "434bbbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float64, numpy=array([ 1.20975673, -0.70145509,  0.9807294 ])>\n"
     ]
    }
   ],
   "source": [
    "print(T3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d408c3c",
   "metadata": {},
   "source": [
    "### 텐서 크기 바꾸기 (tf.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b334c0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. , 3. , 3.5],\n",
       "       [4. , 5. , 6. , 6.5],\n",
       "       [7. , 8. , 9. , 9.5]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "627e49e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.  2.  3.  3.5 4.  5.  6.  6.5 7.  8.  9.  9.5]]]\n"
     ]
    }
   ],
   "source": [
    "T4 = tf.reshape(T1, shape =[1,1,-1])\n",
    "print(T4.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f2f6f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "T5 = tf.reshape(T1, shape = [1,3,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af0f13eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.  2.  3.  3.5]\n",
      "  [4.  5.  6.  6.5]\n",
      "  [7.  8.  9.  9.5]]]\n"
     ]
    }
   ],
   "source": [
    "print(T5.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9240c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T5.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e778a7e1",
   "metadata": {},
   "source": [
    "### 배열 전치 tf.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "691973f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.  2.  3.  3.5]\n",
      "  [4.  5.  6.  6.5]\n",
      "  [7.  8.  9.  9.5]]]\n"
     ]
    }
   ],
   "source": [
    "print(T5.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26717ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. ]\n",
      "  [4. ]\n",
      "  [7. ]]\n",
      "\n",
      " [[2. ]\n",
      "  [5. ]\n",
      "  [8. ]]\n",
      "\n",
      " [[3. ]\n",
      "  [6. ]\n",
      "  [9. ]]\n",
      "\n",
      " [[3.5]\n",
      "  [6.5]\n",
      "  [9.5]]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.transpose(T5).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb14fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. ]\n",
      "  [4. ]\n",
      "  [7. ]]\n",
      "\n",
      " [[2. ]\n",
      "  [5. ]\n",
      "  [8. ]]\n",
      "\n",
      " [[3. ]\n",
      "  [6. ]\n",
      "  [9. ]]\n",
      "\n",
      " [[3.5]\n",
      "  [6.5]\n",
      "  [9.5]]]\n"
     ]
    }
   ],
   "source": [
    "T6 = tf.transpose(T5, perm = [2,1,0])\n",
    "print(T6.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0ed49fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.  4.  7. ]\n",
      "  [2.  5.  8. ]\n",
      "  [3.  6.  9. ]\n",
      "  [3.5 6.5 9.5]]]\n"
     ]
    }
   ],
   "source": [
    "T7 = tf.transpose(T5, perm = [0,2,1])\n",
    "print(T7.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597636d",
   "metadata": {},
   "source": [
    "### 작은 텐서의 리스트로 나누기 tf.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e4e699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.  2.  3.  3.5]\n",
      "  [4.  5.  6.  6.5]\n",
      "  [7.  8.  9.  9.5]]]\n"
     ]
    }
   ],
   "source": [
    "print(T5.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4ba3488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1, 3, 2), dtype=float64, numpy=\n",
      "array([[[1., 2.],\n",
      "        [4., 5.],\n",
      "        [7., 8.]]])>, <tf.Tensor: shape=(1, 3, 2), dtype=float64, numpy=\n",
      "array([[[3. , 3.5],\n",
      "        [6. , 6.5],\n",
      "        [9. , 9.5]]])>]\n"
     ]
    }
   ],
   "source": [
    "t5_splt = tf.split(T5, num_or_size_splits=2,\n",
    "                  axis = 2)#작은 텐서의 리스트로 나누기\n",
    "print(t5_splt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43586953",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(1,25,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd3f7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "T8 = tf.Variable(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7502ed8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T8.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65b0260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T8 = tf.reshape(T8, shape=[2,3,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "133655b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15, 16],\n",
       "        [17, 18, 19, 20],\n",
       "        [21, 22, 23, 24]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T8.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01dffd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T8.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17dfd099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=\n",
      "array([[[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]],\n",
      "\n",
      "       [[13, 14, 15, 16],\n",
      "        [17, 18, 19, 20],\n",
      "        [21, 22, 23, 24]]])>]\n"
     ]
    }
   ],
   "source": [
    "print(tf.split(T8, num_or_size_splits=1, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16c12a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1, 3, 4), dtype=int32, numpy=\n",
      "array([[[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]]])>, <tf.Tensor: shape=(1, 3, 4), dtype=int32, numpy=\n",
      "array([[[13, 14, 15, 16],\n",
      "        [17, 18, 19, 20],\n",
      "        [21, 22, 23, 24]]])>]\n"
     ]
    }
   ],
   "source": [
    "print(tf.split(T8, num_or_size_splits=2, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e9ddfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=\n",
      "array([[[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]],\n",
      "\n",
      "       [[13, 14, 15, 16],\n",
      "        [17, 18, 19, 20],\n",
      "        [21, 22, 23, 24]]])>]\n"
     ]
    }
   ],
   "source": [
    "print(tf.split(T8, num_or_size_splits=1, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fab15123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=\n",
      "array([[[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]],\n",
      "\n",
      "       [[13, 14, 15, 16],\n",
      "        [17, 18, 19, 20],\n",
      "        [21, 22, 23, 24]]])>]\n"
     ]
    }
   ],
   "source": [
    "print(tf.split(T8, num_or_size_splits=1, axis = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "be4ff265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(2, 1, 4), dtype=int32, numpy=\n",
      "array([[[ 1,  2,  3,  4]],\n",
      "\n",
      "       [[13, 14, 15, 16]]])>, <tf.Tensor: shape=(2, 1, 4), dtype=int32, numpy=\n",
      "array([[[ 5,  6,  7,  8]],\n",
      "\n",
      "       [[17, 18, 19, 20]]])>, <tf.Tensor: shape=(2, 1, 4), dtype=int32, numpy=\n",
      "array([[[ 9, 10, 11, 12]],\n",
      "\n",
      "       [[21, 22, 23, 24]]])>]\n"
     ]
    }
   ],
   "source": [
    "print(tf.split(T8, num_or_size_splits=3, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3654702e",
   "metadata": {},
   "source": [
    "어느 기준으로 나눠지는지 잘 모르겠음.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3783cb",
   "metadata": {},
   "source": [
    "### 텐서 연결하여 하나의 큰 텐서로 만듦 tf.concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "79bbe6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.ones(shape=(5,1),dtype=tf.float32)\n",
    "t2 = tf.zeros(shape=(5,1),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "844f9c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]], shape=(5, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66d6281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(5, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b31bed88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t3 = tf.concat([t1,t2],axis = 0)#세로 방향으로 연결\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f8ab3494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t4 = tf.concat([t1,t2],axis = 1)#가로 방향으로 연결\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ce56a",
   "metadata": {},
   "source": [
    "### 텐서플로의 계산 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c5d76c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서 2.x에서는 계산 그래프를 만들지 않고 바로 텐서 z를 계산할 수 있음\n",
    "a= tf.constant(1)\n",
    "b = tf.constant(2)\n",
    "c = tf.constant(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f21abf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 2*(a-b)+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "677b3d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c => 1\n"
     ]
    }
   ],
   "source": [
    "print(\"2*(a-b)+c =>\",z.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a88aa",
   "metadata": {},
   "source": [
    "<b>텐서 1.x 버전에서 계산 그래프를 만들고 실행하는 단계</b>\n",
    "1. 비어있는 새로운 계산 그래프를 만든다\n",
    "<br>\n",
    "\n",
    "2. 계산 그래프에 노드(텐서와 연산)를 추가한다\n",
    "<br>\n",
    "\n",
    "3. 그래프를 실행한다<br>\n",
    "    a. 새로운 세션을 시작한다<br>\n",
    "    b. 그래프에 있는 변수를 초기화한다<br>\n",
    "    c. 이 세션에서 계산 그래프를 실행한다<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c11e664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로 1.x 방식\n",
    "g = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "592e4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 노드를 추가\n",
    "with g.as_default():#그래프에 노드 추가\n",
    "    a = tf.constant(1,name='a')\n",
    "    b = tf.constant(2,name='b')\n",
    "    c = tf.constant(3,name='c')\n",
    "    \n",
    "    z = 2*(a-b)+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a62b42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session(graph = g) as sess:#세션 객체를 만듦 -> 실행할 그래프를 매개변수로 전달\n",
    "    print(\"2*(a-b)+c => \",sess.run(z))#그래프에 있는 노드를 실행시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "359e1877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'a' type=Const>,\n",
       " <tf.Operation 'b' type=Const>,\n",
       " <tf.Operation 'c' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'mul/x' type=Const>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'add' type=AddV2>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_operations()#그래프 g에 들어있는 연산 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f5ba8a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'sub' type=Sub>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_operation_by_name('sub')#하나만 출력도 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2eb24a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"a\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 1\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"b\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"c\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"sub\"\n",
       "  op: \"Sub\"\n",
       "  input: \"a\"\n",
       "  input: \"b\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul/x\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul\"\n",
       "  op: \"Mul\"\n",
       "  input: \"mul/x\"\n",
       "  input: \"sub\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"add\"\n",
       "  op: \"AddV2\"\n",
       "  input: \"mul\"\n",
       "  input: \"c\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 716\n",
       "}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.as_graph_def()#포맷팅된 문자열로 그래프 정의 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "495fc353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'c' type=Const>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.as_graph_element('c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb585fab",
   "metadata": {},
   "source": [
    "<b>데코레이터(decorator)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5b027fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c => 1\n"
     ]
    }
   ],
   "source": [
    "#텐서플로 2.x 버전\n",
    "@tf.function #데코레이터: 일반 파이썬 함수를 호출가능한 그래프 객체로 만듦\n",
    "\n",
    "def simple_func():\n",
    "    a = tf.constant(1)\n",
    "    b = tf.constant(2)\n",
    "    c = tf.constant(3)\n",
    "    \n",
    "    z = 2*(a-b)+c\n",
    "    return z\n",
    "\n",
    "print(\"2*(a-b)+c =>\",simple_func().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bb2676a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.eager.def_function.Function'>\n"
     ]
    }
   ],
   "source": [
    "print(simple_func.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0de859f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_func():\n",
    "    a = tf.constant(1, name = 'a')\n",
    "    b = tf.constant(2, name = 'b')\n",
    "    c = tf.constant(3, name = 'c')\n",
    "    \n",
    "    z = 2*(a-b)+c\n",
    "    return z\n",
    "\n",
    "simple_func = tf.function(simple_func)#자동그래프 기능:tf_function으로 감싼 함수 안의 연산은 자동으로 텐서플로 그래프에 포함되어 실행됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "09b06c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c => 1\n"
     ]
    }
   ],
   "source": [
    "print(\"2*(a-b)+c =>\",simple_func().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "81d2c77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'a' type=Const>,\n",
       " <tf.Operation 'b' type=Const>,\n",
       " <tf.Operation 'c' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'mul/x' type=Const>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_func = simple_func.get_concrete_function()\n",
    "con_func.graph.get_operations()#simple_func가 만든 그래프에 있는 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9942c1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"a\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 1\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"b\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"c\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"sub\"\n",
       "  op: \"Sub\"\n",
       "  input: \"a\"\n",
       "  input: \"b\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul/x\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul\"\n",
       "  op: \"Mul\"\n",
       "  input: \"mul/x\"\n",
       "  input: \"sub\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"add\"\n",
       "  op: \"AddV2\"\n",
       "  input: \"mul\"\n",
       "  input: \"c\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity\"\n",
       "  op: \"Identity\"\n",
       "  input: \"add\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 716\n",
       "}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_func.graph.as_graph_def()#그래프 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ee762",
   "metadata": {},
   "source": [
    "### 텐서플로의 변수  tf.Variable (< initial-value >, name = < optional-name >)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e8d7dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w1:0' shape=(2, 4) dtype=int32>\n"
     ]
    }
   ],
   "source": [
    "#텐서플로 1.x 형식의 변수\n",
    "g1 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    w1 = tf.Variable(np.array([[1,2,3,4],[5,6,7,8]]),name='w1')#변수를 그래프에 추가\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e47bc832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'w1/Initializer/initial_value' type=Const>,\n",
       " <tf.Operation 'w1' type=VarHandleOp>,\n",
       " <tf.Operation 'w1/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>,\n",
       " <tf.Operation 'w1/Assign' type=AssignVariableOp>,\n",
       " <tf.Operation 'w1/Read/ReadVariableOp' type=ReadVariableOp>]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "885f9381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"init\"\n",
      "op: \"NoOp\"\n",
      "input: \"^w1/Assign\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#변수를 사용하기 전에 초기화를 해주어야 함\n",
    "with g1.as_default():\n",
    "    init = tf.compat.v1.global_variables_initializer()#global_variables_initializer()함수가 그래프에 있는 변수 초기화 연산을 한꺼번에 도와줌\n",
    "    print(init.node_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "98bf399b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(2, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "with g1.as_default():\n",
    "    w1 = w1 + 1\n",
    "    print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1eebef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session(graph=g1) as sess:\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(w1))#여러번 실행해도\n",
    "    print(sess.run(w1))#변수 값이 증가하지 않고 원래 초깃값에 1을 더한 결과를 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6cfd75",
   "metadata": {},
   "source": [
    ".assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "903556a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4 5]\n",
      " [6 7 8 8]]\n",
      "[[3 4 5 6]\n",
      " [7 8 9 9]]\n"
     ]
    }
   ],
   "source": [
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    w1 = tf.Variable(np.array([[1,2,3,4],[5,6,7,7]]),name = 'w1')\n",
    "    w1 = w1.assign(w1 + 1)\n",
    "\n",
    "with tf.compat.v1.Session(graph = g2) as sess:\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(w1))#드디어\n",
    "    print(sess.run(w1))#바뀜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0b57a",
   "metadata": {},
   "source": [
    "텐서플로 2.x 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2f3496b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w2:0' shape=(2, 4) dtype=int32, numpy=\n",
      "array([[1, 2, 3, 4],\n",
      "       [5, 6, 7, 8]])>\n"
     ]
    }
   ],
   "source": [
    "w2 = tf.Variable(np.array([[1,2,3,4],[5,6,7,8]]), name = 'w2')\n",
    "\n",
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9124d0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3 4 5]\n",
      " [6 7 8 9]], shape=(2, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(w2 + 1)#덧셈연산의 출력 텐서가 아니라 덧셈이 적용된 상수 텐서를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383ce08",
   "metadata": {},
   "source": [
    ".assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ba21d5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 4) dtype=int32, numpy=\n",
       "array([[2, 3, 4, 5],\n",
       "       [6, 7, 8, 9]])>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.assign(w2 + 1)#변수 값을 증가시키려면 assign() 메서트로 반복해서 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e7511b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "print(w2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a9818a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  4  5  6]\n",
      " [ 7  8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "w2.assign(w2 + 1)#호출 결과는 즉각 반영 됨\n",
    "print(w2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4aa6b9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w2:0' shape=(2, 4) dtype=int32, numpy=\n",
      "array([[ 3,  4,  5,  6],\n",
      "       [ 7,  8,  9, 10]])>\n"
     ]
    }
   ],
   "source": [
    "print(w2)#넘파이 속성 바뀐 것을 볼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b20a7f",
   "metadata": {},
   "source": [
    "### tf.keras API\n",
    "<b>Sequential 모델: 층을 순서대로 쌓은 모델</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7caf9e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#간단한 회귀분석 모델 만들기\n",
    "\n",
    "#랜덤한 회귀용 예제 데이터셋 만듦\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "\n",
    "def make_random_data():#하나의 특성을 가진 랜덤한 회귀용 데이터 만들기\n",
    "    x = np.random.uniform(low = -2, high = 2, size = 200)#200개 샘플\n",
    "    y = []\n",
    "    for t in x:\n",
    "        r = np.random.normal(loc = 0.0, scale = (0.5 + t*t/3), size = None)\n",
    "        y.append(r)\n",
    "    \n",
    "    return x, 1.726*x - 0.84 + np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "de63a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = make_random_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e2ae03bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y,'o')\n",
    "plt.show()#회귀용 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9ba8377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 세트와 테스트 세트를 나눔\n",
    "x_train,y_train = x[:150],y[:150]#150개 훈련 세트\n",
    "x_test,y_test = x[150:],y[150:]#50개 테스트 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ff4912a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5d810f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()#Sequential 모델: 층을 순서대로 쌓은 모델\n",
    "#선형 회귀 모델이기에 활성화 함수 설정 x\n",
    "model.add(tf.keras.layers.Dense(units = 1, input_dim = 1))#출력 유닛 하나를 가진 완전 연결층 하나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1c649163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()#네트워크 구조 출력(2개 params: 가중치, 절편)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6000bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss = 'mse')#모델 컴파일(손실함수: 평균 제곱 오차)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a173cbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f0731ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7997 - val_loss: 0.9339\n",
      "Epoch 2/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7918 - val_loss: 0.8967\n",
      "Epoch 3/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7898 - val_loss: 0.9644\n",
      "Epoch 4/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7941 - val_loss: 0.9166\n",
      "Epoch 5/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7992 - val_loss: 0.9025\n",
      "Epoch 6/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7933 - val_loss: 0.9237\n",
      "Epoch 7/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7934 - val_loss: 0.9141\n",
      "Epoch 8/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7766 - val_loss: 0.8746\n",
      "Epoch 9/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8026 - val_loss: 0.8991\n",
      "Epoch 10/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7936 - val_loss: 0.8751\n",
      "Epoch 11/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8002 - val_loss: 0.8975\n",
      "Epoch 12/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7882 - val_loss: 0.8990\n",
      "Epoch 13/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7916 - val_loss: 0.9222\n",
      "Epoch 14/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7853 - val_loss: 0.9224\n",
      "Epoch 15/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7916 - val_loss: 0.9398\n",
      "Epoch 16/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7835 - val_loss: 0.8982\n",
      "Epoch 17/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7915 - val_loss: 0.9447\n",
      "Epoch 18/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7920 - val_loss: 0.9491\n",
      "Epoch 19/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7950 - val_loss: 0.9520\n",
      "Epoch 20/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7953 - val_loss: 0.9139\n",
      "Epoch 21/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7959 - val_loss: 0.8904\n",
      "Epoch 22/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8013 - val_loss: 0.9042\n",
      "Epoch 23/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7898 - val_loss: 0.9526\n",
      "Epoch 24/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7940 - val_loss: 0.9129\n",
      "Epoch 25/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7972 - val_loss: 0.9118\n",
      "Epoch 26/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7966 - val_loss: 0.9348\n",
      "Epoch 27/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7903 - val_loss: 0.9671\n",
      "Epoch 28/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7934 - val_loss: 0.9213\n",
      "Epoch 29/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7720 - val_loss: 0.8730\n",
      "Epoch 30/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7864 - val_loss: 0.9131\n",
      "Epoch 31/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7873 - val_loss: 0.9636\n",
      "Epoch 32/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8028 - val_loss: 0.9674\n",
      "Epoch 33/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7839 - val_loss: 0.8907\n",
      "Epoch 34/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7985 - val_loss: 0.9102\n",
      "Epoch 35/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7970 - val_loss: 0.9081\n",
      "Epoch 36/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7900 - val_loss: 0.9128\n",
      "Epoch 37/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7824 - val_loss: 0.8738\n",
      "Epoch 38/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8002 - val_loss: 0.9021\n",
      "Epoch 39/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7927 - val_loss: 0.8908\n",
      "Epoch 40/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7955 - val_loss: 0.9252\n",
      "Epoch 41/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7926 - val_loss: 0.8969\n",
      "Epoch 42/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7887 - val_loss: 0.8888\n",
      "Epoch 43/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7854 - val_loss: 0.8727\n",
      "Epoch 44/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7907 - val_loss: 0.9543\n",
      "Epoch 45/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7966 - val_loss: 0.9064\n",
      "Epoch 46/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7736 - val_loss: 0.8984\n",
      "Epoch 47/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7920 - val_loss: 0.8914\n",
      "Epoch 48/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7952 - val_loss: 0.9157\n",
      "Epoch 49/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8004 - val_loss: 0.9100\n",
      "Epoch 50/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.7875   - 0s 2ms/step - loss: 0.7963 - val_loss: 0.8802\n",
      "Epoch 51/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7829 - val_loss: 0.9592\n",
      "Epoch 52/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8010 - val_loss: 0.9449\n",
      "Epoch 53/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7916 - val_loss: 0.8777\n",
      "Epoch 54/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7853 - val_loss: 0.9046\n",
      "Epoch 55/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7951 - val_loss: 0.9601\n",
      "Epoch 56/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7937 - val_loss: 0.9618\n",
      "Epoch 57/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7907 - val_loss: 0.9722\n",
      "Epoch 58/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7966 - val_loss: 0.9313\n",
      "Epoch 59/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7842 - val_loss: 0.9528\n",
      "Epoch 60/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7948 - val_loss: 0.9418\n",
      "Epoch 61/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7802 - val_loss: 0.9986\n",
      "Epoch 62/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8025 - val_loss: 0.9516\n",
      "Epoch 63/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7985 - val_loss: 0.9088\n",
      "Epoch 64/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7845 - val_loss: 0.8969\n",
      "Epoch 65/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7912 - val_loss: 0.8906\n",
      "Epoch 66/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8006 - val_loss: 0.9179\n",
      "Epoch 67/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7941 - val_loss: 0.9369\n",
      "Epoch 68/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7960 - val_loss: 0.9416\n",
      "Epoch 69/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7808 - val_loss: 0.9090\n",
      "Epoch 70/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8016 - val_loss: 0.9009\n",
      "Epoch 71/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7978 - val_loss: 0.9234\n",
      "Epoch 72/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7930 - val_loss: 0.8766\n",
      "Epoch 73/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7961 - val_loss: 0.8814\n",
      "Epoch 74/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7984 - val_loss: 0.9046\n",
      "Epoch 75/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7887 - val_loss: 0.8930\n",
      "Epoch 76/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7781 - val_loss: 0.9810\n",
      "Epoch 77/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7850 - val_loss: 0.9369\n",
      "Epoch 78/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7822 - val_loss: 0.8842\n",
      "Epoch 79/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7884 - val_loss: 0.9468\n",
      "Epoch 80/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7941 - val_loss: 0.9729\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7931 - val_loss: 0.9383\n",
      "Epoch 82/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7868 - val_loss: 0.8860\n",
      "Epoch 83/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7719 - val_loss: 0.8781\n",
      "Epoch 84/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7949 - val_loss: 0.8910\n",
      "Epoch 85/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8001 - val_loss: 0.9107\n",
      "Epoch 86/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7976 - val_loss: 0.9298\n",
      "Epoch 87/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7980 - val_loss: 0.9193\n",
      "Epoch 88/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7795 - val_loss: 0.8968\n",
      "Epoch 89/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8006 - val_loss: 0.9265\n",
      "Epoch 90/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7963 - val_loss: 0.9433\n",
      "Epoch 91/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7937 - val_loss: 0.9739\n",
      "Epoch 92/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7895 - val_loss: 0.9835\n",
      "Epoch 93/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.8044 - val_loss: 0.9030\n",
      "Epoch 94/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7847 - val_loss: 0.8669\n",
      "Epoch 95/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7939 - val_loss: 0.9459\n",
      "Epoch 96/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7871 - val_loss: 0.9979\n",
      "Epoch 97/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7960 - val_loss: 0.9340\n",
      "Epoch 98/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7808 - val_loss: 0.8771\n",
      "Epoch 99/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7996 - val_loss: 0.8767\n",
      "Epoch 100/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7921 - val_loss: 0.9229\n",
      "Epoch 101/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7797 - val_loss: 0.8816\n",
      "Epoch 102/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7964 - val_loss: 0.8917\n",
      "Epoch 103/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7863 - val_loss: 0.8680\n",
      "Epoch 104/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7754 - val_loss: 0.9871\n",
      "Epoch 105/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7965 - val_loss: 0.9171\n",
      "Epoch 106/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7924 - val_loss: 0.9213\n",
      "Epoch 107/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7748 - val_loss: 0.8653\n",
      "Epoch 108/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7902 - val_loss: 0.9421\n",
      "Epoch 109/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7932 - val_loss: 0.9600\n",
      "Epoch 110/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8031 - val_loss: 0.9117\n",
      "Epoch 111/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7925 - val_loss: 0.9408\n",
      "Epoch 112/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7913 - val_loss: 0.9618\n",
      "Epoch 113/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7932 - val_loss: 0.9654\n",
      "Epoch 114/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7988 - val_loss: 0.9245\n",
      "Epoch 115/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7973 - val_loss: 0.9082\n",
      "Epoch 116/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7923 - val_loss: 0.9068\n",
      "Epoch 117/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7857 - val_loss: 0.8874\n",
      "Epoch 118/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7808 - val_loss: 0.9764\n",
      "Epoch 119/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7872 - val_loss: 0.8716\n",
      "Epoch 120/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8018 - val_loss: 0.9035\n",
      "Epoch 121/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7964 - val_loss: 0.8852\n",
      "Epoch 122/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7958 - val_loss: 0.8943\n",
      "Epoch 123/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7972 - val_loss: 0.9140\n",
      "Epoch 124/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7966 - val_loss: 0.9390\n",
      "Epoch 125/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7965 - val_loss: 0.8891\n",
      "Epoch 126/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7983 - val_loss: 0.9031\n",
      "Epoch 127/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7828 - val_loss: 0.9124\n",
      "Epoch 128/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8017 - val_loss: 0.8845\n",
      "Epoch 129/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7914 - val_loss: 0.8885\n",
      "Epoch 130/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7999 - val_loss: 0.9140\n",
      "Epoch 131/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7937 - val_loss: 0.8932\n",
      "Epoch 132/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7978 - val_loss: 0.9321\n",
      "Epoch 133/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7953 - val_loss: 0.9108\n",
      "Epoch 134/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7894 - val_loss: 0.8750\n",
      "Epoch 135/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7954 - val_loss: 0.8977\n",
      "Epoch 136/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8007 - val_loss: 0.8985\n",
      "Epoch 137/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7910 - val_loss: 0.9033\n",
      "Epoch 138/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7931 - val_loss: 0.8918\n",
      "Epoch 139/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7889 - val_loss: 0.8938\n",
      "Epoch 140/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7854 - val_loss: 0.9430\n",
      "Epoch 141/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7905 - val_loss: 0.8835\n",
      "Epoch 142/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.761 - 0s 2ms/step - loss: 0.7900 - val_loss: 0.9490\n",
      "Epoch 143/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7832 - val_loss: 0.9104\n",
      "Epoch 144/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7995 - val_loss: 0.8961\n",
      "Epoch 145/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7868 - val_loss: 0.8848\n",
      "Epoch 146/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7916 - val_loss: 0.8888\n",
      "Epoch 147/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7834 - val_loss: 0.9127\n",
      "Epoch 148/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7978 - val_loss: 0.9418\n",
      "Epoch 149/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7824 - val_loss: 0.8713\n",
      "Epoch 150/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7941 - val_loss: 0.9256\n",
      "Epoch 151/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7953 - val_loss: 0.8997\n",
      "Epoch 152/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7893 - val_loss: 0.8807\n",
      "Epoch 153/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7952 - val_loss: 0.8685\n",
      "Epoch 154/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7921 - val_loss: 0.8694\n",
      "Epoch 155/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7989 - val_loss: 0.9011\n",
      "Epoch 156/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7960 - val_loss: 0.9003\n",
      "Epoch 157/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7958 - val_loss: 0.9127\n",
      "Epoch 158/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7941 - val_loss: 0.9409\n",
      "Epoch 159/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7709 - val_loss: 1.0012\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7966 - val_loss: 0.9386\n",
      "Epoch 161/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7749 - val_loss: 0.9336\n",
      "Epoch 162/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7983 - val_loss: 0.8974\n",
      "Epoch 163/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7959 - val_loss: 0.9429\n",
      "Epoch 164/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.8012 - val_loss: 0.9240\n",
      "Epoch 165/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7715 - val_loss: 0.8733\n",
      "Epoch 166/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7940 - val_loss: 0.8756\n",
      "Epoch 167/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7981 - val_loss: 0.8773\n",
      "Epoch 168/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7876 - val_loss: 0.8684\n",
      "Epoch 169/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7998 - val_loss: 0.8922\n",
      "Epoch 170/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7691 - val_loss: 0.9832\n",
      "Epoch 171/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7996 - val_loss: 0.9266\n",
      "Epoch 172/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7975 - val_loss: 0.9287\n",
      "Epoch 173/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7947 - val_loss: 0.8875\n",
      "Epoch 174/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7942 - val_loss: 0.8876\n",
      "Epoch 175/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7889 - val_loss: 0.9095\n",
      "Epoch 176/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7983 - val_loss: 0.9104\n",
      "Epoch 177/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7751 - val_loss: 0.9693\n",
      "Epoch 178/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7834 - val_loss: 0.9911\n",
      "Epoch 179/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7980 - val_loss: 0.8905\n",
      "Epoch 180/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.736 - 0s 2ms/step - loss: 0.7948 - val_loss: 0.8816\n",
      "Epoch 181/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7985 - val_loss: 0.8802\n",
      "Epoch 182/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7734 - val_loss: 0.8990\n",
      "Epoch 183/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7832 - val_loss: 0.9150\n",
      "Epoch 184/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7829 - val_loss: 0.9247\n",
      "Epoch 185/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7938 - val_loss: 0.8963\n",
      "Epoch 186/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7955 - val_loss: 0.9189\n",
      "Epoch 187/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7947 - val_loss: 0.9333\n",
      "Epoch 188/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8001 - val_loss: 0.8962\n",
      "Epoch 189/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7947 - val_loss: 0.9051\n",
      "Epoch 190/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7968 - val_loss: 0.8959\n",
      "Epoch 191/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7788 - val_loss: 0.9553\n",
      "Epoch 192/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7782 - val_loss: 0.8655\n",
      "Epoch 193/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8051 - val_loss: 0.8881\n",
      "Epoch 194/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.7787 - val_loss: 0.9393\n",
      "Epoch 195/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.7971 - val_loss: 0.8846\n",
      "Epoch 196/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7990 - val_loss: 0.8809\n",
      "Epoch 197/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7962 - val_loss: 0.8896\n",
      "Epoch 198/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7999 - val_loss: 0.8928\n",
      "Epoch 199/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7917 - val_loss: 0.8671\n",
      "Epoch 200/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8018 - val_loss: 0.9019\n",
      "Epoch 201/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7851 - val_loss: 0.8985\n",
      "Epoch 202/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7697 - val_loss: 0.8901\n",
      "Epoch 203/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7994 - val_loss: 0.9469\n",
      "Epoch 204/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.7982 - val_loss: 0.8885\n",
      "Epoch 205/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7943 - val_loss: 0.9301\n",
      "Epoch 206/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7971 - val_loss: 0.9068\n",
      "Epoch 207/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7953 - val_loss: 0.9129\n",
      "Epoch 208/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7915 - val_loss: 0.9198\n",
      "Epoch 209/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7994 - val_loss: 0.8834\n",
      "Epoch 210/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7941 - val_loss: 0.8804\n",
      "Epoch 211/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8006 - val_loss: 0.9048\n",
      "Epoch 212/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7919 - val_loss: 0.9374\n",
      "Epoch 213/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8013 - val_loss: 0.9257\n",
      "Epoch 214/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7959 - val_loss: 0.9242\n",
      "Epoch 215/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7903 - val_loss: 0.9420\n",
      "Epoch 216/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7909 - val_loss: 0.9039\n",
      "Epoch 217/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7999 - val_loss: 0.8970\n",
      "Epoch 218/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7813 - val_loss: 0.9418\n",
      "Epoch 219/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7950 - val_loss: 0.9722\n",
      "Epoch 220/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7923 - val_loss: 0.9015\n",
      "Epoch 221/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7996 - val_loss: 0.9186\n",
      "Epoch 222/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.680 - 0s 2ms/step - loss: 0.7761 - val_loss: 0.8799\n",
      "Epoch 223/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7973 - val_loss: 0.8781\n",
      "Epoch 224/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8030 - val_loss: 0.8929\n",
      "Epoch 225/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7889 - val_loss: 0.9282\n",
      "Epoch 226/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7866 - val_loss: 0.8758\n",
      "Epoch 227/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8036 - val_loss: 0.9045\n",
      "Epoch 228/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7987 - val_loss: 0.8991\n",
      "Epoch 229/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7963 - val_loss: 0.8917\n",
      "Epoch 230/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7915 - val_loss: 0.8728\n",
      "Epoch 231/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7833 - val_loss: 0.9912\n",
      "Epoch 232/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8009 - val_loss: 0.9091\n",
      "Epoch 233/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7909 - val_loss: 0.9148\n",
      "Epoch 234/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7974 - val_loss: 0.9002\n",
      "Epoch 235/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7892 - val_loss: 0.9647\n",
      "Epoch 236/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7779 - val_loss: 0.8655\n",
      "Epoch 237/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8039 - val_loss: 0.9009\n",
      "Epoch 238/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7920 - val_loss: 0.8906\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8016 - val_loss: 0.9022\n",
      "Epoch 240/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7905 - val_loss: 0.8796\n",
      "Epoch 241/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7977 - val_loss: 0.9186\n",
      "Epoch 242/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7909 - val_loss: 0.9184\n",
      "Epoch 243/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7994 - val_loss: 0.9098\n",
      "Epoch 244/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7843 - val_loss: 0.8672\n",
      "Epoch 245/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7784 - val_loss: 0.9617\n",
      "Epoch 246/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7913 - val_loss: 0.8995\n",
      "Epoch 247/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7715 - val_loss: 0.9936\n",
      "Epoch 248/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7984 - val_loss: 0.8883\n",
      "Epoch 249/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8004 - val_loss: 0.8819\n",
      "Epoch 250/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7966 - val_loss: 0.8787\n",
      "Epoch 251/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7919 - val_loss: 0.9059\n",
      "Epoch 252/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7921 - val_loss: 0.9032\n",
      "Epoch 253/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7921 - val_loss: 0.8905\n",
      "Epoch 254/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7829 - val_loss: 0.9748\n",
      "Epoch 255/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8052 - val_loss: 0.8934\n",
      "Epoch 256/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7976 - val_loss: 0.9368\n",
      "Epoch 257/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7972 - val_loss: 0.9411\n",
      "Epoch 258/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7990 - val_loss: 0.9334\n",
      "Epoch 259/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7898 - val_loss: 0.8906\n",
      "Epoch 260/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7836 - val_loss: 0.8680\n",
      "Epoch 261/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7929 - val_loss: 0.9114\n",
      "Epoch 262/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7746 - val_loss: 0.8741\n",
      "Epoch 263/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8001 - val_loss: 0.8902\n",
      "Epoch 264/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7966 - val_loss: 0.8878\n",
      "Epoch 265/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.766 - 0s 2ms/step - loss: 0.7884 - val_loss: 0.8913\n",
      "Epoch 266/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7951 - val_loss: 0.8962\n",
      "Epoch 267/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7895 - val_loss: 0.9665\n",
      "Epoch 268/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7916 - val_loss: 0.9127\n",
      "Epoch 269/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7967 - val_loss: 0.8756\n",
      "Epoch 270/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8037 - val_loss: 0.8815\n",
      "Epoch 271/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7951 - val_loss: 0.8900\n",
      "Epoch 272/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7867 - val_loss: 0.8676\n",
      "Epoch 273/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7973 - val_loss: 0.8809\n",
      "Epoch 274/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7909 - val_loss: 0.9127\n",
      "Epoch 275/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7972 - val_loss: 0.9314\n",
      "Epoch 276/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7944 - val_loss: 0.9197\n",
      "Epoch 277/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7909 - val_loss: 0.9314\n",
      "Epoch 278/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8002 - val_loss: 0.9084\n",
      "Epoch 279/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7952 - val_loss: 0.9364\n",
      "Epoch 280/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7621 - val_loss: 0.8798\n",
      "Epoch 281/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7851 - val_loss: 0.8798\n",
      "Epoch 282/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7930 - val_loss: 0.8803\n",
      "Epoch 283/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7818 - val_loss: 0.9546\n",
      "Epoch 284/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7888 - val_loss: 0.8728\n",
      "Epoch 285/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7955 - val_loss: 0.8647\n",
      "Epoch 286/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7836 - val_loss: 0.9289\n",
      "Epoch 287/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7758 - val_loss: 0.8786\n",
      "Epoch 288/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7904 - val_loss: 0.9440\n",
      "Epoch 289/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7675 - val_loss: 1.0120\n",
      "Epoch 290/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8136 - val_loss: 0.8990\n",
      "Epoch 291/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7892 - val_loss: 0.8806\n",
      "Epoch 292/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7822 - val_loss: 0.9189\n",
      "Epoch 293/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7937 - val_loss: 0.9412\n",
      "Epoch 294/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7988 - val_loss: 0.9217\n",
      "Epoch 295/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.779 - 0s 2ms/step - loss: 0.7808 - val_loss: 0.8754\n",
      "Epoch 296/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7810 - val_loss: 0.9873\n",
      "Epoch 297/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7967 - val_loss: 0.8912\n",
      "Epoch 298/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7948 - val_loss: 0.9052\n",
      "Epoch 299/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8001 - val_loss: 0.8886\n",
      "Epoch 300/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8016 - val_loss: 0.8977\n",
      "Epoch 301/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7697 - val_loss: 0.8776\n",
      "Epoch 302/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8037 - val_loss: 0.8997\n",
      "Epoch 303/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7791 - val_loss: 0.8937\n",
      "Epoch 304/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7931 - val_loss: 0.8865\n",
      "Epoch 305/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7972 - val_loss: 0.8973\n",
      "Epoch 306/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7970 - val_loss: 0.9208\n",
      "Epoch 307/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7840 - val_loss: 0.8804\n",
      "Epoch 308/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7868 - val_loss: 0.9668\n",
      "Epoch 309/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8034 - val_loss: 0.9163\n",
      "Epoch 310/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7975 - val_loss: 0.9267\n",
      "Epoch 311/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7917 - val_loss: 0.9007\n",
      "Epoch 312/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7850 - val_loss: 0.9059\n",
      "Epoch 313/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7933 - val_loss: 0.9446\n",
      "Epoch 314/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7993 - val_loss: 0.8918\n",
      "Epoch 315/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7906 - val_loss: 0.8895\n",
      "Epoch 316/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7942 - val_loss: 0.9330\n",
      "Epoch 317/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7850 - val_loss: 0.8839\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7949 - val_loss: 0.9353\n",
      "Epoch 319/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8024 - val_loss: 0.9086\n",
      "Epoch 320/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7881 - val_loss: 0.8705\n",
      "Epoch 321/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7957 - val_loss: 0.9173\n",
      "Epoch 322/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.801 - 0s 2ms/step - loss: 0.7935 - val_loss: 0.9342\n",
      "Epoch 323/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7970 - val_loss: 0.9307\n",
      "Epoch 324/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.664 - 0s 2ms/step - loss: 0.7853 - val_loss: 0.8733\n",
      "Epoch 325/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7936 - val_loss: 0.9294\n",
      "Epoch 326/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8013 - val_loss: 0.9003\n",
      "Epoch 327/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7891 - val_loss: 0.9382\n",
      "Epoch 328/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7788 - val_loss: 0.8694\n",
      "Epoch 329/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7896 - val_loss: 0.9681\n",
      "Epoch 330/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8012 - val_loss: 0.9023\n",
      "Epoch 331/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7928 - val_loss: 0.9055\n",
      "Epoch 332/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7911 - val_loss: 0.8900\n",
      "Epoch 333/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7862 - val_loss: 0.9343\n",
      "Epoch 334/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8052 - val_loss: 0.9035\n",
      "Epoch 335/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7930 - val_loss: 0.8784\n",
      "Epoch 336/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7876 - val_loss: 0.9533\n",
      "Epoch 337/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7956 - val_loss: 0.9366\n",
      "Epoch 338/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7823 - val_loss: 0.9453\n",
      "Epoch 339/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7791 - val_loss: 1.0037\n",
      "Epoch 340/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7865 - val_loss: 0.9027\n",
      "Epoch 341/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7888 - val_loss: 0.9085\n",
      "Epoch 342/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7941 - val_loss: 0.9132\n",
      "Epoch 343/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7937 - val_loss: 0.9480\n",
      "Epoch 344/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7902 - val_loss: 0.8843\n",
      "Epoch 345/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7948 - val_loss: 0.9013\n",
      "Epoch 346/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7999 - val_loss: 0.8867\n",
      "Epoch 347/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7840 - val_loss: 0.8688\n",
      "Epoch 348/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7923 - val_loss: 0.8802\n",
      "Epoch 349/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7864 - val_loss: 0.9419\n",
      "Epoch 350/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7997 - val_loss: 0.8983\n",
      "Epoch 351/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7912 - val_loss: 0.9332\n",
      "Epoch 352/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.854 - 0s 2ms/step - loss: 0.7955 - val_loss: 0.9583\n",
      "Epoch 353/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7884 - val_loss: 0.8768\n",
      "Epoch 354/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7935 - val_loss: 0.9219\n",
      "Epoch 355/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7789 - val_loss: 0.9730\n",
      "Epoch 356/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7922 - val_loss: 0.9034\n",
      "Epoch 357/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7867 - val_loss: 0.8694\n",
      "Epoch 358/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7520 - val_loss: 0.9829\n",
      "Epoch 359/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8009 - val_loss: 0.9100\n",
      "Epoch 360/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7879 - val_loss: 0.9735\n",
      "Epoch 361/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7979 - val_loss: 0.9266\n",
      "Epoch 362/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7863 - val_loss: 0.9026\n",
      "Epoch 363/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7700 - val_loss: 0.9788\n",
      "Epoch 364/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8021 - val_loss: 0.9166\n",
      "Epoch 365/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7914 - val_loss: 0.9667\n",
      "Epoch 366/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8003 - val_loss: 0.9543\n",
      "Epoch 367/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.923 - 0s 2ms/step - loss: 0.7823 - val_loss: 0.8880\n",
      "Epoch 368/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8012 - val_loss: 0.8917\n",
      "Epoch 369/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7863 - val_loss: 0.9111\n",
      "Epoch 370/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7932 - val_loss: 0.9221\n",
      "Epoch 371/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8024 - val_loss: 0.9537\n",
      "Epoch 372/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7684 - val_loss: 0.8742\n",
      "Epoch 373/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8116 - val_loss: 0.9008\n",
      "Epoch 374/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7948 - val_loss: 0.9283\n",
      "Epoch 375/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7963 - val_loss: 0.9051\n",
      "Epoch 376/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7910 - val_loss: 0.8853\n",
      "Epoch 377/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7981 - val_loss: 0.9004\n",
      "Epoch 378/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7657 - val_loss: 0.9963\n",
      "Epoch 379/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7970 - val_loss: 0.9810\n",
      "Epoch 380/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7951 - val_loss: 0.9113\n",
      "Epoch 381/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7893 - val_loss: 0.9294\n",
      "Epoch 382/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7839 - val_loss: 0.9486\n",
      "Epoch 383/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7736 - val_loss: 0.8971\n",
      "Epoch 384/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7716 - val_loss: 0.8916\n",
      "Epoch 385/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8023 - val_loss: 0.9245\n",
      "Epoch 386/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7928 - val_loss: 0.8812\n",
      "Epoch 387/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7872 - val_loss: 0.9024\n",
      "Epoch 388/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7934 - val_loss: 0.9152\n",
      "Epoch 389/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8020 - val_loss: 0.9138\n",
      "Epoch 390/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7881 - val_loss: 0.9163\n",
      "Epoch 391/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7737 - val_loss: 0.8807\n",
      "Epoch 392/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7842 - val_loss: 0.8652\n",
      "Epoch 393/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7893 - val_loss: 0.9565\n",
      "Epoch 394/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7888 - val_loss: 0.8856\n",
      "Epoch 395/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7933 - val_loss: 0.8910\n",
      "Epoch 396/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7947 - val_loss: 0.9358\n",
      "Epoch 397/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7976 - val_loss: 0.9025\n",
      "Epoch 398/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7961 - val_loss: 0.8890\n",
      "Epoch 399/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7893 - val_loss: 0.9482\n",
      "Epoch 400/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7948 - val_loss: 0.9242\n",
      "Epoch 401/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7977 - val_loss: 0.9100\n",
      "Epoch 402/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7902 - val_loss: 0.8880\n",
      "Epoch 403/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7915 - val_loss: 0.9072\n",
      "Epoch 404/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7890 - val_loss: 0.9097\n",
      "Epoch 405/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7955 - val_loss: 0.8838\n",
      "Epoch 406/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7797 - val_loss: 0.8715\n",
      "Epoch 407/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7883 - val_loss: 0.9485\n",
      "Epoch 408/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7801 - val_loss: 0.9671\n",
      "Epoch 409/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7939 - val_loss: 0.8797\n",
      "Epoch 410/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7991 - val_loss: 0.8827\n",
      "Epoch 411/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7806 - val_loss: 0.9562\n",
      "Epoch 412/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7821 - val_loss: 0.8858\n",
      "Epoch 413/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7914 - val_loss: 0.8825\n",
      "Epoch 414/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7948 - val_loss: 0.8801\n",
      "Epoch 415/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7999 - val_loss: 0.8955\n",
      "Epoch 416/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7961 - val_loss: 0.8881\n",
      "Epoch 417/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7983 - val_loss: 0.8871\n",
      "Epoch 418/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7935 - val_loss: 0.9439\n",
      "Epoch 419/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7880 - val_loss: 0.9287\n",
      "Epoch 420/500\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.804 - 0s 2ms/step - loss: 0.7856 - val_loss: 0.8869\n",
      "Epoch 421/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7948 - val_loss: 0.9146\n",
      "Epoch 422/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7960 - val_loss: 0.8860\n",
      "Epoch 423/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8001 - val_loss: 0.8968\n",
      "Epoch 424/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7976 - val_loss: 0.8924\n",
      "Epoch 425/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7838 - val_loss: 0.8916\n",
      "Epoch 426/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7928 - val_loss: 0.8679\n",
      "Epoch 427/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7830 - val_loss: 0.8860\n",
      "Epoch 428/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8077 - val_loss: 0.9114\n",
      "Epoch 429/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7950 - val_loss: 0.9125\n",
      "Epoch 430/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7958 - val_loss: 0.8937\n",
      "Epoch 431/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8011 - val_loss: 0.9011\n",
      "Epoch 432/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7934 - val_loss: 0.8906\n",
      "Epoch 433/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7973 - val_loss: 0.8841\n",
      "Epoch 434/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7956 - val_loss: 0.9109\n",
      "Epoch 435/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7874 - val_loss: 0.8898\n",
      "Epoch 436/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7957 - val_loss: 0.9250\n",
      "Epoch 437/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8001 - val_loss: 0.8972\n",
      "Epoch 438/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7943 - val_loss: 0.9028\n",
      "Epoch 439/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7945 - val_loss: 0.8969\n",
      "Epoch 440/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7935 - val_loss: 0.9511\n",
      "Epoch 441/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7713 - val_loss: 0.8669\n",
      "Epoch 442/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7936 - val_loss: 0.9032\n",
      "Epoch 443/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7953 - val_loss: 0.9312\n",
      "Epoch 444/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7844 - val_loss: 0.8901\n",
      "Epoch 445/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7829 - val_loss: 0.8770\n",
      "Epoch 446/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7952 - val_loss: 0.8785\n",
      "Epoch 447/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7911 - val_loss: 0.9395\n",
      "Epoch 448/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8004 - val_loss: 0.9048\n",
      "Epoch 449/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7965 - val_loss: 0.8814\n",
      "Epoch 450/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7973 - val_loss: 0.9055\n",
      "Epoch 451/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7947 - val_loss: 0.9011\n",
      "Epoch 452/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7957 - val_loss: 0.9341\n",
      "Epoch 453/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7978 - val_loss: 0.9174\n",
      "Epoch 454/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8002 - val_loss: 0.8791\n",
      "Epoch 455/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7934 - val_loss: 0.9026\n",
      "Epoch 456/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7932 - val_loss: 0.9317\n",
      "Epoch 457/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7919 - val_loss: 0.8843\n",
      "Epoch 458/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7996 - val_loss: 0.9102\n",
      "Epoch 459/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7936 - val_loss: 0.9107\n",
      "Epoch 460/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7727 - val_loss: 0.9052\n",
      "Epoch 461/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7956 - val_loss: 0.9103\n",
      "Epoch 462/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7796 - val_loss: 0.8662\n",
      "Epoch 463/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8022 - val_loss: 0.9037\n",
      "Epoch 464/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7886 - val_loss: 0.8735\n",
      "Epoch 465/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8021 - val_loss: 0.9099\n",
      "Epoch 466/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7945 - val_loss: 0.8903\n",
      "Epoch 467/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7899 - val_loss: 0.9424\n",
      "Epoch 468/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8008 - val_loss: 0.9045\n",
      "Epoch 469/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7963 - val_loss: 0.9087\n",
      "Epoch 470/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7848 - val_loss: 0.8787\n",
      "Epoch 471/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7999 - val_loss: 0.8865\n",
      "Epoch 472/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7952 - val_loss: 0.9138\n",
      "Epoch 473/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7997 - val_loss: 0.9251\n",
      "Epoch 474/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7989 - val_loss: 0.9549\n",
      "Epoch 475/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7978 - val_loss: 0.9058\n",
      "Epoch 476/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7856 - val_loss: 0.8711\n",
      "Epoch 477/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7948 - val_loss: 0.8783\n",
      "Epoch 478/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7890 - val_loss: 0.8719\n",
      "Epoch 479/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7968 - val_loss: 0.8802\n",
      "Epoch 480/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7800 - val_loss: 0.8839\n",
      "Epoch 481/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8061 - val_loss: 0.9017\n",
      "Epoch 482/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7940 - val_loss: 0.8896\n",
      "Epoch 483/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7981 - val_loss: 0.8886\n",
      "Epoch 484/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7903 - val_loss: 0.8738\n",
      "Epoch 485/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.8013 - val_loss: 0.9046\n",
      "Epoch 486/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7840 - val_loss: 0.9853\n",
      "Epoch 487/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7944 - val_loss: 0.8906\n",
      "Epoch 488/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7885 - val_loss: 0.9547\n",
      "Epoch 489/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7978 - val_loss: 0.8927\n",
      "Epoch 490/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7985 - val_loss: 0.8977\n",
      "Epoch 491/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7981 - val_loss: 0.9303\n",
      "Epoch 492/500\n",
      "105/105 [==============================] - 0s 4ms/step - loss: 0.7943 - val_loss: 0.9080\n",
      "Epoch 493/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7869 - val_loss: 0.8893\n",
      "Epoch 494/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7943 - val_loss: 0.9039\n",
      "Epoch 495/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7921 - val_loss: 0.8737\n",
      "Epoch 496/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7954 - val_loss: 0.9233\n",
      "Epoch 497/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7994 - val_loss: 0.9040\n",
      "Epoch 498/500\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7968 - val_loss: 0.8997\n",
      "Epoch 499/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7930 - val_loss: 0.8902\n",
      "Epoch 500/500\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7990 - val_loss: 0.8961\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=1,epochs=500, \n",
    "                    validation_split= 0.3)#훈련세트 학습(검증세트크기: 30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c3da6c",
   "metadata": {},
   "source": [
    "Loss 매개변수 적용 분야:\n",
    "- 회귀 문제: 평균 제곱 오차(mean squared error), <b>mse</b>\n",
    "<br>\n",
    "\n",
    "- 회귀 문제: 평균 절대값 오차(mean absolute error), <b>mae</b>\n",
    "<br>\n",
    "\n",
    "- 다중 크래스 분류 문제: 범주형 크로스 엔트로피(categorical crossentropy), <b>categorical_crossentropy</b>\n",
    "<br>\n",
    "\n",
    "- 이진 분류 문재: 이진 크로스 엔트로피(binary cross entropy), <b>binary_crossentropy</b>\n",
    "\n",
    "<br><br>\n",
    "옵티마이저 종류:\n",
    "- RMSprop 알고리즘: <b>rmsprop</b>\n",
    "<br>\n",
    "\n",
    "- Adagrad: <b>adagrad</b>\n",
    "<br>\n",
    "\n",
    "- Adam: <b>adam</b>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "verbose 매개변수:\n",
    "- verbose = 0: 아무것도 출력 x\n",
    "- verbose = 1: 진행바와 함께 검증 점수를 출력해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e6e45de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, 500+1)\n",
    "plt.plot(epochs, history.history['loss'], label = 'Training loss')#에포크마다 계산한 손실함수 값\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()########??????????????????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38463264",
   "metadata": {},
   "source": [
    "### 함수형 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dc28af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#함수형 api로 모델 생성\n",
    "from tensorflow.keras import Model, Input\n",
    "input = tf.keras.Input(shape=(1,))#Input 클래스의 객체 생성\n",
    "output = tf.keras.layers.Dense(1)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3db6556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = tf.keras.layers.Dense(1)(input)과 동일\n",
    "dense = tf.keras.layers.Dense(1)\n",
    "output = dense(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fe921e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = tf.keras.layers.Dense(1)(input)과 동일\n",
    "dense = tf.keras.layers.Dense(1)\n",
    "output = dense.__call__(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "de2010a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(input, output)#Model 클래스에 입력(input)과 출력(output)을 전달하여 신경망 모델을 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ccbdee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()#모델 구조 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d4782112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss = 'mse')#컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fdb20701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.8446 - val_loss: 1.3921\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6723 - val_loss: 1.2971\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.5221 - val_loss: 1.2146\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.3919 - val_loss: 1.1432\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.2782 - val_loss: 1.0907\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.1939 - val_loss: 1.0486\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.1244 - val_loss: 1.0172\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0738 - val_loss: 0.9821\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0132 - val_loss: 0.9586\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9712 - val_loss: 0.9420\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9414 - val_loss: 0.9274\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9138 - val_loss: 0.9134\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8868 - val_loss: 0.9040\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8683 - val_loss: 0.8956\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8493 - val_loss: 0.8895\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8331 - val_loss: 0.8860\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8232 - val_loss: 0.8819\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8142 - val_loss: 0.8805\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8074 - val_loss: 0.8782\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8031 - val_loss: 0.8759\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7968 - val_loss: 0.8742\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7919 - val_loss: 0.8725\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7855 - val_loss: 0.8727\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7809 - val_loss: 0.8717\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7766 - val_loss: 0.8724\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7746 - val_loss: 0.8739\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7734 - val_loss: 0.8722\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7697 - val_loss: 0.8749\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7677 - val_loss: 0.8766\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7643 - val_loss: 0.8772\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7654 - val_loss: 0.8784\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7647 - val_loss: 0.8780\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7631 - val_loss: 0.8775\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7631 - val_loss: 0.8788\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7610 - val_loss: 0.8785\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7612 - val_loss: 0.8783\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7614 - val_loss: 0.8798\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7600 - val_loss: 0.8806\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7601 - val_loss: 0.8818\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7600 - val_loss: 0.8831\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7605 - val_loss: 0.8851\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7584 - val_loss: 0.8850\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7588 - val_loss: 0.8850\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7584 - val_loss: 0.8903\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7588 - val_loss: 0.8995\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7579 - val_loss: 0.8997\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7560 - val_loss: 0.9043\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9042\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7573 - val_loss: 0.9034\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7557 - val_loss: 0.9034\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7560 - val_loss: 0.9040\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7582 - val_loss: 0.9007\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7559 - val_loss: 0.9008\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7561 - val_loss: 0.9029\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7562 - val_loss: 0.9026\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7577 - val_loss: 0.9015\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7559 - val_loss: 0.9014\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7567 - val_loss: 0.9037\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7566 - val_loss: 0.9078\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7566 - val_loss: 0.9064\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7562 - val_loss: 0.9046\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7562 - val_loss: 0.9013\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7565 - val_loss: 0.9003\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7572 - val_loss: 0.8983\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7562 - val_loss: 0.9014\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7584 - val_loss: 0.9011\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7570 - val_loss: 0.9017\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7569 - val_loss: 0.9002\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7559 - val_loss: 0.9023\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7560 - val_loss: 0.9088\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7558 - val_loss: 0.9069\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7555 - val_loss: 0.9050\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7578 - val_loss: 0.9097\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.794 - 0s 10ms/step - loss: 0.7562 - val_loss: 0.9049\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7570 - val_loss: 0.9039\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7564 - val_loss: 0.8980\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7561 - val_loss: 0.8993\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7575 - val_loss: 0.9077\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7560 - val_loss: 0.9081\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7570 - val_loss: 0.9104\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7563 - val_loss: 0.9105\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9130\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7572 - val_loss: 0.9162\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7561 - val_loss: 0.9167\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7563 - val_loss: 0.9170\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7572 - val_loss: 0.9201\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7575 - val_loss: 0.9195\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7574 - val_loss: 0.9189\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7577 - val_loss: 0.9189\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7572 - val_loss: 0.9191\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7573 - val_loss: 0.9183\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7570 - val_loss: 0.9152\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9194\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7567 - val_loss: 0.9163\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7571 - val_loss: 0.9174\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7568 - val_loss: 0.9141\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7570 - val_loss: 0.9174\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7564 - val_loss: 0.9155\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9135\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9124\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7571 - val_loss: 0.9107\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7567 - val_loss: 0.9111\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9130\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7560 - val_loss: 0.9135\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7582 - val_loss: 0.9079\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7569 - val_loss: 0.9067\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.9069\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7563 - val_loss: 0.9113\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7564 - val_loss: 0.9090\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7584 - val_loss: 0.9062\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7570 - val_loss: 0.9064\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7573 - val_loss: 0.9124\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7563 - val_loss: 0.9106\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7560 - val_loss: 0.9077\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7570 - val_loss: 0.9065\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7557 - val_loss: 0.9054\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7578 - val_loss: 0.9028\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9027\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7562 - val_loss: 0.9050\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7570 - val_loss: 0.9009\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7568 - val_loss: 0.9031\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7578 - val_loss: 0.9038\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7569 - val_loss: 0.9032\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7567 - val_loss: 0.9042\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7569 - val_loss: 0.9033\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7567 - val_loss: 0.9068\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7561 - val_loss: 0.9088\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7566 - val_loss: 0.9042\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7572 - val_loss: 0.9021\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7570 - val_loss: 0.9023\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9050\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7567 - val_loss: 0.9034\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7566 - val_loss: 0.9030\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7560 - val_loss: 0.9012\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7566 - val_loss: 0.9036\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7566 - val_loss: 0.9033\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7558 - val_loss: 0.9017\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7556 - val_loss: 0.9022\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7571 - val_loss: 0.9004\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9033\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7558 - val_loss: 0.9007\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7560 - val_loss: 0.8994\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7562 - val_loss: 0.9016\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7560 - val_loss: 0.9014\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7576 - val_loss: 0.9010\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7564 - val_loss: 0.9028\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7559 - val_loss: 0.9053\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7586 - val_loss: 0.9044\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7568 - val_loss: 0.9039\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7559 - val_loss: 0.9044\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7556 - val_loss: 0.9061\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7568 - val_loss: 0.9093\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7565 - val_loss: 0.9082\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.9080\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7577 - val_loss: 0.9123\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7562 - val_loss: 0.9091\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7564 - val_loss: 0.9070\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7566 - val_loss: 0.9002\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7563 - val_loss: 0.9008\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7558 - val_loss: 0.9004\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7565 - val_loss: 0.8991\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7571 - val_loss: 0.8972\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7575 - val_loss: 0.8969\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7560 - val_loss: 0.8988\n",
      "Epoch 165/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7573 - val_loss: 0.9000\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7558 - val_loss: 0.9001\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7559 - val_loss: 0.8986\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 0.9003\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7562 - val_loss: 0.8993\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7570 - val_loss: 0.9016\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7565 - val_loss: 0.9008\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7581 - val_loss: 0.9015\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7568 - val_loss: 0.8995\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7570 - val_loss: 0.8965\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7564 - val_loss: 0.8968\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7564 - val_loss: 0.8984\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7566 - val_loss: 0.8990\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7568 - val_loss: 0.9022\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7567 - val_loss: 0.9034\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 0.9000\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7574 - val_loss: 0.8975\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.8992\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7570 - val_loss: 0.9014\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7561 - val_loss: 0.9038\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7566 - val_loss: 0.9025\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7564 - val_loss: 0.9050\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7561 - val_loss: 0.9037\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7563 - val_loss: 0.9032\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7564 - val_loss: 0.9045\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7576 - val_loss: 0.9084\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7569 - val_loss: 0.9059\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7563 - val_loss: 0.9113\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7578 - val_loss: 0.9068\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7572 - val_loss: 0.9093\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.564 - 0s 9ms/step - loss: 0.7566 - val_loss: 0.9136\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7566 - val_loss: 0.9112\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7570 - val_loss: 0.9103\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 0.9110\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7558 - val_loss: 0.9095\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7562 - val_loss: 0.9083\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7558 - val_loss: 0.9054\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7566 - val_loss: 0.9046\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7575 - val_loss: 0.9029\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7559 - val_loss: 0.9045\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7569 - val_loss: 0.9008\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 0.9053\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7575 - val_loss: 0.9031\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7559 - val_loss: 0.9043\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7564 - val_loss: 0.9070\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7558 - val_loss: 0.9053\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7567 - val_loss: 0.9039\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9020\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7575 - val_loss: 0.9057\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7559 - val_loss: 0.9051\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7568 - val_loss: 0.9054\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7571 - val_loss: 0.9018\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7569 - val_loss: 0.9016\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7567 - val_loss: 0.9025\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7583 - val_loss: 0.9013\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7587 - val_loss: 0.8990\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7569 - val_loss: 0.9046\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7574 - val_loss: 0.9116\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7578 - val_loss: 0.9073\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7568 - val_loss: 0.9054\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7563 - val_loss: 0.9058\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7566 - val_loss: 0.9047\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7563 - val_loss: 0.9011\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.8974\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7576 - val_loss: 0.8964\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7566 - val_loss: 0.8960\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7566 - val_loss: 0.8966\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 0.8968\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7564 - val_loss: 0.8954\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7566 - val_loss: 0.8985\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7569 - val_loss: 0.8961\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7569 - val_loss: 0.8927\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7572 - val_loss: 0.8934\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7569 - val_loss: 0.8923\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7583 - val_loss: 0.8908\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7574 - val_loss: 0.8969\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 0.8952\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7576 - val_loss: 0.8981\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 0.8975\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7571 - val_loss: 0.8980\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7566 - val_loss: 0.8985\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7561 - val_loss: 0.8966\n",
      "Epoch 247/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7570 - val_loss: 0.8938\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7578 - val_loss: 0.8971\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7566 - val_loss: 0.8956\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7567 - val_loss: 0.8972\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7560 - val_loss: 0.8969\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.653 - 0s 10ms/step - loss: 0.7566 - val_loss: 0.8995\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7564 - val_loss: 0.8975\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7588 - val_loss: 0.8964\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7570 - val_loss: 0.8988\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7560 - val_loss: 0.8985\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7574 - val_loss: 0.8991\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7560 - val_loss: 0.9020\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.565 - 0s 10ms/step - loss: 0.7558 - val_loss: 0.9048\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7590 - val_loss: 0.9023\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7558 - val_loss: 0.9032\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7570 - val_loss: 0.9005\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 0.8989\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7566 - val_loss: 0.8989\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7558 - val_loss: 0.9005\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7581 - val_loss: 0.9019\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7557 - val_loss: 0.9017\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7564 - val_loss: 0.9080\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.9107\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7564 - val_loss: 0.9132\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7567 - val_loss: 0.9142\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7569 - val_loss: 0.9120\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7568 - val_loss: 0.9146\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.9147\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7573 - val_loss: 0.9153\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7568 - val_loss: 0.9138\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7562 - val_loss: 0.9110\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9072\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.925 - 0s 11ms/step - loss: 0.7570 - val_loss: 0.9086\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.9055\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7560 - val_loss: 0.9087\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7561 - val_loss: 0.9061\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7565 - val_loss: 0.9036\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.8999\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7572 - val_loss: 0.8984\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7568 - val_loss: 0.8964\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 0.8951\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7574 - val_loss: 0.8934\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7579 - val_loss: 0.8939\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7564 - val_loss: 0.8962\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7567 - val_loss: 0.8966\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7564 - val_loss: 0.8965\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7583 - val_loss: 0.9023\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.9013\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9023\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7568 - val_loss: 0.9001\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7571 - val_loss: 0.8997\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9000\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7566 - val_loss: 0.8972\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7589 - val_loss: 0.8991\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.8983\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7571 - val_loss: 0.8984\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7558 - val_loss: 0.9000\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.652 - 0s 9ms/step - loss: 0.7564 - val_loss: 0.8964\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7580 - val_loss: 0.8964\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7572 - val_loss: 0.8946\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7584 - val_loss: 0.8945\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7574 - val_loss: 0.8958\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7586 - val_loss: 0.8949\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7581 - val_loss: 0.8929\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7587 - val_loss: 0.8923\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7589 - val_loss: 0.8939\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7576 - val_loss: 0.8944\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7577 - val_loss: 0.8955\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7572 - val_loss: 0.8939\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7574 - val_loss: 0.8936\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7579 - val_loss: 0.8956\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7588 - val_loss: 0.8973\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7582 - val_loss: 0.8983\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7570 - val_loss: 0.9008\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7594 - val_loss: 0.8998\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7588 - val_loss: 0.9016\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9032\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7564 - val_loss: 0.9016\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9048\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7566 - val_loss: 0.9042\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7569 - val_loss: 0.9047\n",
      "Epoch 328/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7584 - val_loss: 0.9040\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9046\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9025\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7579 - val_loss: 0.9027\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7573 - val_loss: 0.9027\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7570 - val_loss: 0.9021\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7559 - val_loss: 0.9021\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7588 - val_loss: 0.9035\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7568 - val_loss: 0.9026\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.9041\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7575 - val_loss: 0.9002\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7563 - val_loss: 0.8985\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7565 - val_loss: 0.8979\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7561 - val_loss: 0.8959\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7570 - val_loss: 0.9016\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7557 - val_loss: 0.9021\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7564 - val_loss: 0.8989\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7564 - val_loss: 0.9016\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7576 - val_loss: 0.9101\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7567 - val_loss: 0.9108\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7569 - val_loss: 0.9051\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9036\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7568 - val_loss: 0.9003\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7573 - val_loss: 0.9017\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9074\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7562 - val_loss: 0.9072\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9060\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7563 - val_loss: 0.9077\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7558 - val_loss: 0.9052\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7560 - val_loss: 0.9084\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7573 - val_loss: 0.9096\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7561 - val_loss: 0.9083\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.705 - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9067\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7569 - val_loss: 0.9107\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.671 - 0s 10ms/step - loss: 0.7573 - val_loss: 0.9058\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7566 - val_loss: 0.9058\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7569 - val_loss: 0.9057\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7556 - val_loss: 0.9055\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7557 - val_loss: 0.9072\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7571 - val_loss: 0.9085\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7569 - val_loss: 0.9047\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7575 - val_loss: 0.9069\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7574 - val_loss: 0.9042\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7558 - val_loss: 0.9046\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7562 - val_loss: 0.9047\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7564 - val_loss: 0.9050\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7556 - val_loss: 0.9022\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7565 - val_loss: 0.8985\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7571 - val_loss: 0.9010\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7558 - val_loss: 0.9030\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9049\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7555 - val_loss: 0.9061\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7556 - val_loss: 0.9062\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7568 - val_loss: 0.9060\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7564 - val_loss: 0.9047\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9030\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7560 - val_loss: 0.9056\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7562 - val_loss: 0.9088\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7564 - val_loss: 0.9090\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7562 - val_loss: 0.9063\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7562 - val_loss: 0.9035\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7560 - val_loss: 0.9026\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7574 - val_loss: 0.8993\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7566 - val_loss: 0.9068\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7563 - val_loss: 0.9058\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7562 - val_loss: 0.9040\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9065\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7580 - val_loss: 0.9046\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7568 - val_loss: 0.9081\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7569 - val_loss: 0.9093\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7574 - val_loss: 0.9089\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7568 - val_loss: 0.9061\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7580 - val_loss: 0.9075\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7567 - val_loss: 0.9060\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7566 - val_loss: 0.9020\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7562 - val_loss: 0.9002\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7566 - val_loss: 0.9010\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7569 - val_loss: 0.9012\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7558 - val_loss: 0.9050\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7568 - val_loss: 0.9033\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7562 - val_loss: 0.9053\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7558 - val_loss: 0.9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7582 - val_loss: 0.9109\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7565 - val_loss: 0.9070\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7559 - val_loss: 0.9041\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7568 - val_loss: 0.9023\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7564 - val_loss: 0.8995\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7571 - val_loss: 0.8977\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7572 - val_loss: 0.9060\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7556 - val_loss: 0.9061\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7559 - val_loss: 0.9047\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9031\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7579 - val_loss: 0.9010\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7559 - val_loss: 0.9008\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7565 - val_loss: 0.9047\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7564 - val_loss: 0.9071\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7561 - val_loss: 0.9090\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7568 - val_loss: 0.9109\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7563 - val_loss: 0.9124\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7572 - val_loss: 0.9087\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7564 - val_loss: 0.9076\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7572 - val_loss: 0.9027\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7559 - val_loss: 0.9080\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7573 - val_loss: 0.9096\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7560 - val_loss: 0.9099\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7564 - val_loss: 0.9101\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7562 - val_loss: 0.9128\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7575 - val_loss: 0.9150\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7564 - val_loss: 0.9130\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7563 - val_loss: 0.9097\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7565 - val_loss: 0.9081\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7563 - val_loss: 0.9080\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7572 - val_loss: 0.9140\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7574 - val_loss: 0.9126\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7558 - val_loss: 0.9141\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7571 - val_loss: 0.9115\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9086\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7558 - val_loss: 0.9071\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9107\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7567 - val_loss: 0.9182\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7569 - val_loss: 0.9182\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7568 - val_loss: 0.9214\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7575 - val_loss: 0.9192\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7569 - val_loss: 0.9204\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7572 - val_loss: 0.9157\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7569 - val_loss: 0.9161\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7566 - val_loss: 0.9146\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7559 - val_loss: 0.9117\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7559 - val_loss: 0.9097\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7563 - val_loss: 0.9120\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7577 - val_loss: 0.9092\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 0.9050\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7565 - val_loss: 0.9015\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7559 - val_loss: 0.8990\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7572 - val_loss: 0.8990\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7559 - val_loss: 0.8990\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7563 - val_loss: 0.8992\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7570 - val_loss: 0.9013\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7575 - val_loss: 0.8966\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7573 - val_loss: 0.8981\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7569 - val_loss: 0.8995\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.8984\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7578 - val_loss: 0.8948\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7578 - val_loss: 0.8962\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7574 - val_loss: 0.8992\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7566 - val_loss: 0.8976\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7570 - val_loss: 0.8965\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7567 - val_loss: 0.8982\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7566 - val_loss: 0.9022\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7561 - val_loss: 0.9015\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7568 - val_loss: 0.9040\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7561 - val_loss: 0.9033\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7577 - val_loss: 0.9064\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.446 - 0s 9ms/step - loss: 0.7560 - val_loss: 0.9063\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7594 - val_loss: 0.9070\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.9103\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7569 - val_loss: 0.9085\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7573 - val_loss: 0.9037\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 0.9014\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7570 - val_loss: 0.8994\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7558 - val_loss: 0.9004\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7561 - val_loss: 0.9027\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7583 - val_loss: 0.9034\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7574 - val_loss: 0.9047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.9021\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7567 - val_loss: 0.9013\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7558 - val_loss: 0.9021\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7572 - val_loss: 0.8986\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7565 - val_loss: 0.8987\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7567 - val_loss: 0.8989\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7566 - val_loss: 0.9030\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7563 - val_loss: 0.9033\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7558 - val_loss: 0.9035\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=500, validation_split=0.3)#훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1d8c8ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, history.history['loss'], label = 'Training loss')#훈련 손실\n",
    "plt.plot(epochs, history.history['val_loss'],label = 'Validation loss')#검증 손실\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()#검훈련 손실과 검증 손실 그래프(뭔가 이상함 책 내용과 다름)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2c2ef1",
   "metadata": {},
   "source": [
    "### tf.keras 모델의 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3f1f575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simple_wights.h5')#모델 가중치 HDF5 파일 포맷으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5923b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units = 1, input_dim = 1))\n",
    "model.compile(optimizer = 'sgd', loss='mse')\n",
    "model.load_weights('simple_wights.h5')#가중치 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4aee0875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.946718156337738"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "99932af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('simple_model.h5')#가중치와 네트워크 구조까지 포함하여 tf.keras 모델 저장(HDF5파일 포맷)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "61e308a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.946718156337738"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('simple_model.h5')#저장된 모델 로드\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "25f1790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EarlyStopping(ModelCheckpoint 콜백과 함께 사용)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units = 1, input_dim = 1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "#모니터 대상: 검증 손실\n",
    "callback_list = [tf.keras.callbacks.ModelCheckpoint(filepath='my_model.h5', monitor='val_loss', \n",
    "                                                    save_best_only=True),#최상의 모델 가중치 저장\n",
    "                 #지정한 에포크 횟수(patience) 동안 모니터링 지표가 개선되지 않으면 훈련을 중지\n",
    "                tf.keras.callbacks.EarlyStopping(patience=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "302658b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 2.8761 - val_loss: 1.5139\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.5133 - val_loss: 1.3493\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.2096 - val_loss: 1.2179\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.9611 - val_loss: 1.1157\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.7587 - val_loss: 1.0333\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.5906 - val_loss: 0.9681\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.4525 - val_loss: 0.9185\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.3386 - val_loss: 0.8774\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2395 - val_loss: 0.8477\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.1643 - val_loss: 0.8244\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.1006 - val_loss: 0.8082\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0466 - val_loss: 0.7957\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0024 - val_loss: 0.7867\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9654 - val_loss: 0.7810\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9364 - val_loss: 0.7776\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9124 - val_loss: 0.7755\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8900 - val_loss: 0.7752\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8724 - val_loss: 0.7757\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8589 - val_loss: 0.7770\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8473 - val_loss: 0.7786\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8378 - val_loss: 0.7809\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs= 500, validation_split=0.2, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a1a979e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/04_05.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-f5962b7044ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/04_05.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#d파일 경로가 달라서 안되는 듯\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#손실그래프(epoch = 500인데 검증 손실이 감소되지 않아 훈련이 일찍 멈춤)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\dsfs\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\dsfs\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3003\u001b[0m                 \u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3005\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3007\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\dsfs\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2253\u001b[0m                 \u001b[1;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2254\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2255\u001b[1;33m                     result = print_method(\n\u001b[0m\u001b[0;32m   2256\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2257\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\dsfs\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\dsfs\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[0;32m    507\u001b[0m         \"\"\"\n\u001b[0;32m    508\u001b[0m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m         mpl.image.imsave(\n\u001b[0m\u001b[0;32m    510\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"upper\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m             dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\dsfs\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1614\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"format\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1615\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dpi\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1616\u001b[1;33m         \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\dsfs\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2167\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2168\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2169\u001b[1;33m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/04_05.png'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#손실 그래프 시각화를 통해 훈련이 일찍 멈춘 것 확인\n",
    "epochs = np.arange(1, len(history.history['loss'])+1)\n",
    "plt.plot(epochs, history.history['loss'], label = 'Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label = 'Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('/04_05.png',dpi=300) #d파일 경로가 달라서 안되는 듯\n",
    "plt.show()#손실그래프(epoch = 500인데 검증 손실이 감소되지 않아 훈련이 일찍 멈춤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5fb6e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('simple_model.h5')#저장된 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bcc2d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('my_model.h5')#저장된 가중치 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "69dce3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0269039869308472"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fc9a7d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAy30lEQVR4nO2deXxU9bn/309CIsRogQTCEgkuvdZW6wZetSoqVSu1Iq5ItCouFbtgba/Vcntb25+3Vlt7bbGt1OUiScQqILjQqhXsra1KtIqKVtSKRBADKIvIljy/P74ZM5k5Z9Yzy5k879drXpM5c5bvOQyf85zn+yyiqhiGYRjhpazQAzAMwzCyw4TcMAwj5JiQG4ZhhBwTcsMwjJBjQm4YhhFy+hTioLW1tTpy5MhCHNowDCO0PPfcc2tVdVDs8oII+ciRI2ltbS3EoQ3DMEKLiKzwWm6uFcMwjJBjQm4YhhFyTMgNwzBCjgm5YRhGyDEhNwzDCDkm5IZhlCTNzTByJJSVuffm5kKPKHcUJPzQMAwjlzQ3w2WXwZYt7vOKFe4zQGNj4caVK8wiNwyj5Jg2rVvEI2zZ4paXIibkhmGUHO+8k97ysGNCbhhGyTFiRHrLw05gQi4i5SLyDxF5KKh9GoZhZML110NVVc9lVVVueSkSpEU+FXg1wP0ZhmFkRGMjzJgBDQ0g4t5nzCjNiU4ISMhFpB74MnB7EPszDMPIlsZGePtt6Ox076Uq4hCcRf4/wNVAp98KInKZiLSKSGt7e3tAhzUMwzCyFnIROQV4X1WfS7Seqs5Q1VGqOmrQoLhyuoZhGEaGBJEQ9AXgVBEZB/QFdheRJlU9L4B9G4ZhFIS2NliyBNrbYdAgGD0a6usLPSpvsrbIVfVaVa1X1ZHAROAJE3HDMMJMWxvMn++SiOrq3Pv8+W55MWJx5IZhGDEsWQL9+8Puu7taLbvv7j4vWVLokXkTqJCr6mJVPSXIfRqGYeSb9naoru65rLraLS9GzCI3DMOIYdAg2Ly557LNm93yYsSE3DAMI4bRo+HDD2HjRheHvnGj+zx6dKFH5o0JuWEYRgz19TB+vEvrX7PGvY8fX7xRK1aP3DAMw4P6+sTC3dzsyuK+844rxnX99YXLHjUhNwzDSJNia1xhrhXDMIw0KbbGFSbkhmEYaVJsjStMyA3DMNKk2BpXmJAbhmGkSbE1rjAhNwzDSEJzM4wc6dL1R450y5I1rojdprk5d+OzqBXDMIwE+EWozJjhGlaksw3kJqpFVDX4vSZh1KhR2tramvfjGoZhpMvIkU6IY2lo8BfyTLZJBRF5TlVHxS4314phGEYCMolQyXdUiwm5YRhGAjKJUMl3VIsJuWEYoaKtDebNcz7qefNy3+zh+uuhb9+ey/r2TRyhku+oFhNywzBCQyE694wZA+ecAzU17nNNjfs8Zkz8upFIlfPPh3793Lp+US1BYlErhmGEhujOPdD9vmRJ7ioTLlkCJ5wAZ5zRvWzjxvhjxkaqrFvnrPBZs3Jff8UscsMwQkMhOvekesxC1l8xITcMIzQk6twTRAKO1z6ij7l4MVx8MZx2mhPo6GMUsv6KCblhGKHBr3PPypXOrbFiBah2J+CkI+YR10jsPlaudMdYuBB+/etuS3zt2p7HKGT9FUsIMgwjVLS1Of90e7uzlkePhqOOyj4BJ1ESz1//Cgcf7MTb7xixPnJwPvIgJzn9EoJMyA3DCD1lZc6KjkXEWe5B7COVY+S6a5BldhqGUbIkc2uk4j9Pto9UXCeNjc467+x07/nqFmRCbhhG6EmUgOPn+44V82RJPMVWurYHqpr316GHHqqGYRhB0tSk2tCgKuLem5rc8oYGVSfhPV8NDanvI9Xvcw3Qqh6aaj5ywzCKkqD8zUH4z4sF85EbhhEaUnWHpEKxtWXLBSbkhtFLyWcHm3QJMkuyqH3bAZG1kIvIHiKySESWicgrIjI1iIEZhpE7grR4c0GQWZKNjS6WO1L0ClxBq5yxeTNs2pTDA8QThEW+E/iOqn4WOBz4uoh8NoD9GoaRIwpZFyQVgnaHPPUUrF/f/XnduoBvXNu3w4MPwrnnwuDBcPvtAe04NbIWclVdrarPd/29CXgVGJ7tfg3DyB2FqguSai3xIN0hzc3wu9/FT3hmfePq7IS//AUuvxyGDoVTT4XZs+Hjj6GlJYsdp0+gPnIRGQkcDDzj8d1lItIqIq3tuSxVZhhGUgoxAZhOLfGIOyRRl/pUmTbNO2oFMrhxqcKLL8L3vucmFsaMgdtu62nuA2zdmlf3SmDhhyJSDTwJXK+qcxOta+GHhlFY8lEXJJZ589zxIjXEwRW9qqqCCRNyc0zwDz+ENGqx/OtfcM89ztJ+5RXvdUaMcK6VxkY44IBMh5uQnIYfikgFMAdoTibihmEUnmiLF6C8vNvVkKsJz0R1vXMZQeP3lCGSxFXT3g633gpf+ALstZe7OLEiPnCgc6383/85sb/hBl8Rz+U5Zt0hSEQEuAN4VVVvzn5IhmHkg4jlHW2ZR6JXor8Pikhd72iLfPNmWLYMfv/73I3h+uvjnz5EnP7G7X/TJufvaWmBRx+Fjo74HVZVOX94YyOceCJUViYdQ+wTUODX2SvdM50XcBSgwFLgha7XuETbWIq+YQRLpqnj6aSvZ8vKlarTp7uxPfCAe58+XXXYsOBS6P1IuN22baoLFqhOnKjar5/3YMrLVceNU21uVt20Ke1zD+o6Yyn6hlGaZOPvznf6ulct8REjUhtDoH79zk5XZLy5Ge67Dz74wHu9o46CSZPgzDPdgDMkqOts9cgNo0RJ1BAh2UReNtsGRapjSNb4IfYGEdeMWRWWLnVuk3vuca1/vDjgADdpee657qABENR1tlorhlGiZBMTXgzp66mOwe98VqxIEtb4r3+5ne2/Pxx0ENx4Y7yIjxgB11zjhH7pUrj22sBEHHJ/nU3IDSOEREdAlPn8L04lJjzIeO1MSXUMfudTWwv9+7tJ1LIy914n77Puuulw5JEu4uQ//9PNqkZTUwNTpnRHnPz0p1mHDfpFpuT6OptrxTBChpevOJZcx4QXAj8f+cSJLoikYusmhj7zAMOfbKH2hcco6/SJODntNOf3PvFEqKjI+fisZ6dhGHH4+VsjNDQE3yuyWIitUf7T67Yz8rU/MnRxC3s8v4Dy7R/Hb9SnD5x0khPv8eNh111zMrZ8zDeYkBtGiRBIpmKY6ex07pCWloQRJ9tGf4FdLmqEs85y/pcck48IID8hzzohyDCM/DJihL9FnuuiVwUjUuMkEnHiU21r3fADWH1cIzVfn8jQwxvyOsShQ2HVqvjl+WhgYZOdhhEyrr/eWXleZCsaRdds4q233Al/7nNw8MFw003xIt7Q4KJMli6lpm0p+8/6Xt5FvK0NTjgh3uXet2+eIoC8soRy/bLMTsPIjilTXJZidJZgVVV2zYCbmtw+ovcZOUa6jYYjmZSRpMi09rFmjeqvf616+OHe6ZCgWlPjLsJf/6ra0ZHZCQfI3Lnu3E4+WbWsrPvanXRSsMfBJ7PThNwwQkrQHd390sjTvVF43RCS7mPjRtW773bKF1H+2Neuu6o2Nqo+/LDq9u3ZnazHmLO5lrfdpvrtb6tWVvYcckVF9v8u0ZiQG0YvIhNhirXwM60NkuyG8Mk+tm1TnT9f9eyzVfv29V65Tx/VU05RbWlR3bw508uREK8bT7pPN3PnuoeEXNetMSE3jF5CMmHyE/lkAhxxFyQj0Q1B6NAxLFa99FLVAQP8Vzz6aNXf/la1vT2r65DKzSyIglYrV2Z3zVLFhNwwCkTQLpBkJBKmRCKfyCWSnUXeqQfyD72R7+pKhvvv/POf1+fPuUGPHP521tcqHSvb78aTrgCnU8UxU0zIDaMABPHYni6JhCmZ9Rk9SZnpZGrknPfkTZ3GT/QV9kt8Z7j2WtWXXgr0WqVjZQdVYjYf/9Ym5IZRAPJZ7zuVY6ZjfWb0JPHee6q/+pW+v0+CiJPaWtUrrlB96inVzs6Uxp0u6Z5nUAKc66cvE3LDKABBPbYnIlY8pkzxF6ac3Fg2bFCdOTO1iJNHHvGNOEnoW89xw4x8u78yxYTcMApAri1yP2tyyhRvYQrM+ty61bX5CTDiJJXJ1uixrlzpokVuu829r1yZ/LoUq0Cnigm5YRSAXAtKJjeKVKxPT5Hs6FBdtCh5xMlRR2UUcZLKZGvk3PzaxsWKeRis7HTwE3IrmmUYOSa2Yl+QlQlzUaiprc01ZujfH6p3VSpeeYGhTzRzwLLZ9HnvXe+NDjzQVRecODGlOgF+1yR6uZ80icCcOa5cbHQj540bXdnYCRPSP+ewYEWzDKNANDbmrqSsXwGtVGquePXPrK93y+q3vcm+j7Qw/C8t7Nb2mvcORo504n3uua77Took6ygfuVZ+ZWFHjHBjrqvruby6GtasSXkYJYUVzTKMHJFuAapMClZ5tRAD2Lw58fYRqzu6Pdqjs9bw4Y9/xZHfOZzx39mHz7T8V7yI19bC178OTz3VXdAqDREHZ3HHNsXYssUtT3ZukfZogwa5c4w95yz6I4cas8gNIwckszqzXT9C5LupU2Hduu7l69Yl3n7JEuc6GdhnI0MWzWP4X1qofeFxyjTeH7Njl115Yc8JPL3nJPa46IuMOqIivrFxGqTaYzQybi8XTORGBM4S37wZPvwQxozJfFxhxnzkhpED0u0Wk213mbS237aNP317Ifu/2MKQ1gcp3741bruOsj6sPvBklo+exD0fncq28iqOOcaVZf3wQ9doJ1MxD6qTjp9rKFvS2W8u5z+8sA5BhpFH0p2EzHbSMtn2LbM6ePA//sLYNS2cVXY/n+r80HM/az97NLXfamTVkWfyzBs1PPoo7LKLm8uMNNnJdlIxH70tM6XHRG+Upe914yrEedhkp2HkkXQnIf3WHzoU5s1Lbh16b6+cXPcPln25hTELZzNJuyJOYm4MSzmAZhq5v8+5TP3aCL71NRgGTDige1KxLGo2LdNJxWjrdeBA6NcP1q/PjyWbKhGXUyQaJvK+ZEn8dU/k68/3udhkp2HkgHHj0lvuNbHXt6/rOhM9ITl/vneXs+jt9+YN/pOf8Br78fB7h/LZR37B8IiId/E2Dfw317I/L3EgS7mR7/HWzhHcfHPP/cZOKq5dC4sWwfPPuxuMT8e1OCLW64oV7slh3Tr4+GOYNcu5U4pBxMHduKqrey6rrnbLY0nV158PzCI3jBzwyCPpLY+d2Bs4ELZtg5kz3Tbnnw/HHuvWibUOm5vhf655j4u3/IHzaOYwnvU8Rju13Ms5tDCJv3MEEN8vLlaERo/unlTcutX1PFaFY47pvrH4+cujLfCyMujo6Pn9li1w9dXuBhS0nztTIjeu6Ph0v2iYbEI/g8YscsPIEq+wwUystcZGZ53OmuWs1Ygl3N4O06fD4sUx1uHGjfztazMZ8tUTebptOL9iapyIb2ZXZnEe43iYYazim0zn7xyJl4hDvAjV1zuhrqqC1lbndjj2WBg82Ild//7uxuJ1TaIt8FgRj7BqVWpPHKnQ1uaeEmbMSO9pIZrRo51PfONGN7ewcaP7PHp0/LqJwiPzTSAWuYh8CbgFKAduV9UbgtivYRQ7fmGDAwf2DAeMkIq15uV73b7dCfyoA7bx+bcWwtkt8OCDHLk1PuJkB31YyMm0MIkH+Qpb2DWlc/ETofp690rHX+51Dl7U1KTmj05G9CRlXZ27CSZ6WvAjcuNassSd16BBLqTRax+JwiPzTdZCLiLlwK3ACUAbsEREFqjqsmz3bRjFjt+EV79+ThhjIxpSsdZirXahk2P4C43tzUy44n76fvyh53ZPcgwtTOJ+zmQ9Nb77F4mPcKmpgVtuSSxC6bgdUvETV1Q4S/fii7tdK+edB5/5TPJtY0lnkjIZkRtXKuQyazcdgnCtHAa8oapvqep2YDYwPoD9GkbR4ydY69e7R/yGBiecDQ1wwQVO+JNlbg4cCKAcxD+4ie/yDiNYzHFcyu1xIr6s4kCu5meMYAXH8iQz+FpCEa+pgcsv7zmupiY3iZlMkNJxO/g9eZSXdx/3+OPhz3/udhVFXEjLMjAB05mkLEWCEPLhwMqoz21dy3ogIpeJSKuItLb3lqtrlDyJwgkjPu/OTmeJz5zZ7TOOuGBixXz+zW/yjQ9/wjI+yz84hO/yC+qJKVQ1ciR8//vw8sv8464XuLXqalaS2gzbunVuHNdf78YVGzHi5e+P+J4feQQqK53/fs0a94Th57rw8x/PnNl93Jdegh07eq6zYwfcd19Kp9KDXp+y71USMZ0XcCbOLx75fD4wPdE2VsbWKBVSLVPrV262vFz1/lvfU73lFtV//3ff2q3t1OqmC76u+re/9eiqExlDpFxrTY1qRUVqpWBTOZe+fVUvuCBxudhE1yZRGdkguxWlUta2FCBX9ciBI4A/RX2+Frg20TYm5EYpkUrd61jR2o0N+lX+V//IibqTMk9F28Suejfn6Uks1D5s17lz0x9Poo47sfjdbGpqVBcs6H41NWnKY0lEqrXUU71ZJmo0USr4CXnWKfoi0gd4HRgLvAssASap6it+21iKvtHbGDkSVq/YxskspJFmTuEh+hEfcbKdih4RJx/j/BO1tc5dESmElc5xU61r4pfmD7BgQfffnZ3OtZLuWGJJNcU9qNospYBfin7WFnnXjWAcTszfBKYlW98sciNMZNNppvnunTp+9yd0Bpfoevr7msiLOUYv43c6kLVxX5eVqZ53XmZWcDodipJZ5FddpTpokFtWWxtMx51MnmYSPVUEQTF3FsJavfWORy8jWDJq1dbZqfrcc7rs5Ku0jWG+4v08B+l3uVHrecfXBbLbbqpjx7ruapn+XlMVpkQ+8ilT4n3v+eqBmeu+p9EUe6/PXi/kvWUyxAiWtERk+XLV665T3XdfX/F+kz31J0zT/Xgl6YTkbrupXnGF6jXXqN5wg/8Yg7Qgp0xxE7CRidgpU9z/kerq/IlpLPkU13zeNDLBT8h7Ta2VIBMGjN5D0lT7996De++FlhZ41rvGyfsM4l7O4R7O9a1xEktlJVx6qUuHj5SN9SLThhR++5o5szudvqPDfYb40L4I+SgQlc8MymIqhJUOvaYe+YwZ8enFQU3aGKWL10Tb7mzg0pp5/PyQFpfR4lUwvLqaOTqB3380icf5Ih1p2EwDBrgexiedlLgett/4ILOJQL99lZf710optQnHYp9Y9Zvs7DVFs3p9woCREZHElkq2cRrz+ANnsYY6fr7uInjssZ4iXlEBX/kKzJ4Na9aw9ba7eaLiS2mJeEMDLF3qLPLJk13K+n//Nzz5pPf6QVqQftv4iTgUpkBULimmQljp0GuEPJ30YqO4yaRJcUZ0dNA49AleHH0J7VLHPE7nLO6nL9t6rjdmDNx2m3OzLFgA55wDVVU0NsIll6R3yHfecaL929+6NH9wFQInT/Y+z0SZpemSKK3ei5qa4qgzEiSNjfGlFYqhc1FSvBznuX5Z1IqRKV4TXyJuUi4QOjtVW1tdrN0w/4iTdQ0Hqd54o8695R3ficYpUxJPZvpNqtXUeH9XU9N9DaIzOSsrg5kI9JtUnDKluCM5ehP09qgVozTwiyqICF3G4vL662lFnCQTuKam9EU8USZm5OUlthUV7tyDiFrxi4Ap5tjq3oSfkPeayU6jNEiUfQhpNr+NRJw0N3t3RwA6agdz+6ZzuGvbJJ7h34mOOPGbBGxocO9ek2YRKirgiCPcOitWeJeW9aKhobgn44zc4jfZaUJuhAq/qIJoEorahg2ulF+Lf8TJJqp5dNfTGfD1SWwcPZYJZ6UXpStdWp/ov9Z558GwYbD33i6sbu3a5PutqXF+c6/9ingHzxilRa+PWjFKg+uv7xZKP1as6DkxeM9dW/na4HncL2eyrX8dXBQfcdJRXsGD5eM5m3upYw1nfjSTr0w/iQcX9qG21vs4fuMYMSLxZOPRR7uOP8OHu5DYVES8osI1fghyctPInLxNuKeKl78l1y/zkRvZkMokYnW/nfrYNY/r8jGT9QM+5e+UPvZY1Rkz9ID69Z6r1Na648VOKJaXq37pS/5p601NLr09dn/77OP2d8st3dUEI/VLYl/l5d6+apt4LCyF/DfAJjuNUsI7sqNTD2WJ/oJv67sM9VX55zlI/1//m3qELSWaaJw+3YlvbW33f9pLL+0uJBUZS+wkYFNTd+DLwIGqU6e6Q952mysTERHyq65Kr46JTTwWlkKm8fsJufnIDU+am+NToqE4Gs1GxhdJTd+H5UyihUm0sC+ve67/Jnt1rTGJ19gvzqecKKPvr391c6Ht7fD88y73YPDg7nXSzRCeN8+NO7r35cKFrjPOunWFv7ZGYvwm3PMxT+HnI+81tVaM1PGq3zF5svvxRlpzZVPTI/o4md4YGo9fzb6n30ufP7Rw0HbviJP2ssE8tOs5/G5TI89yGNERJ7E+5Uitb69mydHNeCMiHE26GcKjR7sO7+D6Sm7eDJ/7nOveZnV/ip8RI7xv+oWcp7DJzhIi0ltxxgz33taW2X68OsNv3x7fX3HLFrduJkRuFsl6WPZgwwa46y444QSor2dU07fjRHwT1czkq5y6y5947K53qfztr3i5qmfYoFfKdaoZfUFkCNfXu9opVVXJe18axUH05Obmza6EQjSFTuM310qJ0NbmrLz+/butvETFlhKRLCokdt1MHidTLk60davr+tvSAg89BNu2xW9UUcHKz4/jpysa+d+1pzC4oV8P6z4by9+LtrZuV8ugQU7ETYRLF69ORhUVzjW2fn1+XWHmWilxgirT29ycenIKJH+c9BPRhMWeOjpg8WK38Zw5zuyNRcTVeJ00Cc44gz0GDOA3wPejRPbKK53fefVqd+xZs4L5zxbtaikF7MaUGK8n1B07nMGUSuhoPjAhLxHa211McjTV1e7RPR2mTUtdxAHGjfP/LlGt7Hg/o3Ioz3F5dQvsMduprxcHH+zU+Jxz4tQm+qnktdfgN78J1qdfikRfs7o69yQ3f765eqIJQ41y85GXCEGV6U33x/nII91/x/ror7463pLZsgUuuMDdAKqq4NO8zg/5Ef9kX1oZzSWbfhkv4nvvDT/4AQ/+bBkj1z9P2X98h5FH1cf506OfSpqagvXpQxEmgQRA9DUrK3Pv/fv7VizolYQhCcss8hAT/UhcVuZKh+y5Z08f+Zgx6e3Tb0bej4jwe1l2q1Z5bzOoYzW73T6bZf1baNjiM1cyeLDrrjBpEhx2GM0tEmfdX3QRTJ3a7accOxZOPdV9396eeLzpEmQnnmIiqCe5UiZRRFOxYEIeUryEU8T92D76yFniY8ak/3js96Pt18/FOMcSsUq8fPQ1Nd3b7M4GzmAOk2jhOBZRvqMTYsV2t93g9NOdeB9/PPTp/nn6+Skj+1+xAu6+G3bZxY21rMx7EnbgwJQvRQ+8jh+x8MMs5JEnueiYdmu40pN8tprLFBPykOIlnCNHOtGdMCHz/fr9aCGxVeJl2U2etJUVv3mYszta+DIPxzdkADf9P26cO/AppzgV9iAVS3rnThed2NHhH0mzaZOzrtP9TxgGP2kmeMW0Z/IkV+o0NhaXcMdiQh5ScvlI7PWjbW52GhsR8poaV8Qpst4nlt2uHdS+tIjhT7Zw0t/mUNkRH3HSifAkY/jjwEZ+9sYZrkllElJ1+Wzdmvj77dt7WtGpRmwUYxJIEERi2pcscb+dTJ/kjMJiQh5S8vlI7BVH+/HHUSuocmRFK6vvaGHf52fTb8N7nvt5noNpppF7OYcPquqZ8SvAR8NjBfboo9Pz3ScikV/fL2IjDH7STCm1cMreiAl5SMnnI7Gff/j2q1+ncXkLtLRQt3w5dV4b77UXNDbyYPW5fPM3+33irpnh42Nsa4M//tGVCq+rgwMOcMd6+OHgzieRXz+yPFbYwuAnNXovvTL8MIxhZLFjfvLJ/KV5R/uBh7KKK/klzzKaRav2heuug+XLe24weDB861vw97/DG2/Aj3/MV67ej7ffdr7rt9/2F/H58+Hll2HoUNeBZ8kS5w754INgziXWr19d3fP76mr/iJfGRpKeg2EUgl5nkYcxjMxvzEF39/bLwvxc/QZGr3QRJ8fzBGV4ZAwliDhJlYiFvGOHey/rMjOWL4fa2tSz6GpqnCC/8053lIpXKrVFbBilQq+rtZJyjY8iIh9jvuIK+N3vurM6d2Erp1c+zA0HtjD8hYcp3xEfcdJRXkH5V77sxDtBxEmqzJjh3CnPPONKqlRVufF88IF7v+MOZ51HqKhwIZfRy9Lp2RlkfRrDyAc5afUmIjeJyGsislRE5olI/2z2lw/CGEaW6zE3NzsRF+1gLI9zB5NZQx0t289kxJK5PUS8E+FvuxzH0xf/nvL2NS6F86yzUhLxZC6tiIX86U+7WPhITHxFhSvzetNNPasT3nUX3Hln8oqFflgVQqNUyMoiF5ETgSdUdaeI/AxAVb+XbDuzyNOjttY7GaemJoCiPaqcOqyV495rYSKzGYp3xAmHHOIs74kTXbPJNPGKfIm1nqMt5K1b4aWX4P334bjj4OSTTWANw88iD8y1IiITgDNVNak9VEghT0VQio2cCPnrr7vSsC0t8ZOVXbzB3jzyqXP51t8nwX77ZXggR6o3UKvEZxj+5KOM7WTg3gQDuAy4DGBEAbMowhhGtn59est9WbUK7r3XibfPjXQNg5nNRJpppJXRzLpVIDsNB1J3D1lMs2GkT1KLXEQeB4Z4fDVNVed3rTMNGAWcrimY+NZYIj2ycgd9+CHMneseRRYt8qxRu6Pvbty743RmdjSyiOPoiLq/NzQEc6MLo0vLMIqNjC1yVf1ikh1fCJwCjE1FxI30STurcOtWl0HT0uLevbrqVFa6GieTJlFxyinI3H4snwYdK3o2lggqPLOUMyMNo+CoasYv4EvAMmBQOtsdeuihaqRHU5NqQ4OqiHtvaopZYedO1cceU73wQtXdd1d1WtzzJaJ63HGqt9+uun6953EaGrw3bWjIwzkEvJ1hlBpAq3poarZRK28AuwCRqbinVfXyZNuZayUgVJ2vu6UFZs92Bcm9OOSQ7q46SSJOysr8OwTddlv6E5DZTl6GcXLaMHJFzqNW0qE3C3kiYUtZ9F5/3SlcS4tLgfdi772d0p17LnzmMymPz8+XXVPjEnLSSZoJIuHGfOuG0U1OEoJKgUzrrmSyXUTYtmxxGYxbtrjPbW2JvwNcxMkvfwmjRsG++8KPfxwv4nV1rmXOM8+4kMLrrktLxMH5rKuqei6rqHDt2dJtBRZEG7EwJnAZRr4Jfa2VbB7dM6274rfdU0+5HpZ+YY2Jqu1B/HcVH33I+zfMpf5V/4iTT2qcNDa6zJkMapxEExueOWCAE/Fjj+1eJ9W650HUTC/VOuCGESShdq1k++ie6WO733axxPpyI7VEyqKegzo7u4Wtrg767NxK3ZKHGP5kC4NbH6Z85/b4HVdWwpe/7HY8blzWNU4SMW+eu2FFF5bauDG1TkTZbBshtgYMmI/c6L3kIyEo76RTT9qLTB/bU32sj+3p6Fttb2AHg156gqFNLYx4bi4VW+K76iDiLO7GRmeB9++f2iCyJJu659nWTG9uhpkze4q4iHtCMBE3jG5CLeTt7fDaa9DU1O1aOe+81N3CmT62p9NpPlr0ewjbrsouS5ew/6IW9n9ltitA5cH2Aw6l8sJJrDpmIs+sHObOc1H+UtezaQWWbRsxr4YWqs59ZRhGFF4xibl+BRVHPnWqakVFz3jnigq3PBWamlSrqnpuX1WVPE7Zazu/V2z89erFr+mys/9LPxy8j+9GHw7eR5ed/UNdvfg1VVVduVJ1+nR33AcecO/Tp7vl2ZKPGO1MjyHiHw5vGL0RfOLIQy3kw4Z5/0cfNiz1fWSbpJJIxD+5KbS1qf7iF6qHHOK/8pAhqldeqfrss6qdnT2ONXeu28+CBd2vpia3PB1iz3XKlMxuZOkeM9Nj5DI5yTDCiJ+Qh3qy0y95RcRNIuYDr4QVgL0GfEDz6XM4/K0WWLzYc6Db++1O5cQzXKz38ce73mYeJJokjUTZZDLO6FT8aIKM0c4mDtySgQyjJyUZR+7ny85naFpjoxOWhgbox8dMqb2Pdw6dwJsfDeHwOy6NCxvcRiVzOJ0zuJ+hvEfz2DvhhBN8RRy6J0mjSbclmZ+/2YsgY7SziQOPvraZNI4wjN5CqIXcK3kl6EJMiRJ/mpth74adzDzvMX6+9kI29K3jN2vPZo/nHujZf0yEp/oez2TuoI41nMkc5nIG6z/ux7RpyccwerSL9ti40VniGze6z6NHJx6ziAsrF0l9chaCvRFme7O1hseGkQJe/pZcv7LxkXv5eXM1Wefr353VqQt/9LTe2udbupo6f7/3qFGqN9+s+u67WU/crVzpfOK33ebe/SY605mIjRy/WH3khmH0hFKY7ExFFFIVvFSInWzbl1f1On6gy9nbVxnf6rOP6g9/qPrPfybcV64m7pJNwMZeu9gbYS5ujFa90DCCoSSEPJkYBh2mJ6I6jDa9ip9rK/4RJ6sYor9kqo7iWRU6PfeVL8vUz/KPtcK9BLXQ1rMJvmEkxk/IQ5UQlGziLNtMz0/44AOYM4e/VrZw+LbFlBE/K7iB3ZnDGTTTyGKOpRM3WdnQ4L3LfLWYS5asNGAALF3qfT28JkRjs1NzRaZ1bwzDCNlkZ7KJs/Z2lwoeTXW1Wx5L7CTm7Ls+hvvugwkT6Bg8BC69lCO3Leoh4pGIk9OZQx1ruJg7eYKxn4h4MXS88ZoAjlBZCRMn+lcfLGSlwUQ3EcMwEhMqizxZuzDfWiYxYXoR62/blp18kSeYtKKFcZPnApsAiA4E7ER4guNpYRLzy05nfWd/z7El622ZL4sz2vJfEdW2bdAgOP98OOYY/+qDhaw0aOVqDSMLvPwtuX4FGbUSO9GZ1Efe2anjhzyt/0PiiJNnGaVXcrMO5d1P/PBhy1KMzQi96irVmhrtcT7RFNJHblmchpEcSmGyMxV8o1ZefVX1Bz9Q3ds/4uR19tEf8UP9N17zDRNMNiHn930h6oZE39i+/e34ujReIl2oCcdCT7QaRhjoNULeg5UrVX/+c9WDD/YV71UM0Zu5UkfxrDaM6MzKMkwkRn77HTgw+zDJZJdg7lx3nGK3eC1qxTAS4yfkoa614sn69TBnjutn+eSTTq9i2N5vd2ZvP4OZHd0RJ5EaHpB5fY9EdUW8/PsVFfCNb8Chh6bfyzJdEjVVLsBPwDCMDCjJWiuf8PHH8Ic/wGmnwZAhTjFjC1VVVrqGDPffT+X6NZTPvJM3G8aiUt6jhkd0fQ9wJVAi0RPJ+nImmrCL3W9NDXzzm65XRCa9LJMRG5UzcKD3eiKp9yk1DKM4Ca9FvnMn/PnPzvKeOze+qhQ4lTr+eKeiEyak1VUn1cp70T1Dp02DtWvj9xVb6c+rmuGiRa4bzgcfdMeYjxmTWT9Sr7FXVvYs/5JofIZhFCd+Fnm4hFzVdYhvaYF774X33/c7gFPbc86BoUN9d5eocXMq5Vdje4b+6U9w++2wY0f3+l7iH9vLcvFi+PWve27Xt68b/gknpN+PNNWeohHyWfbXMIzMCb9r5c47YZ994IgjnOrFiPiOPT8NP/oR/POfTp2vvDKpiM+f7wS1rs69z5/vloO/m2TFim5XRHQmaVkZnHwyXHIJ1NYmLrsaW81w5syeIg6wdSs89FD3vtNxv6Qbe20d6Q0j3IQnIWjLFnjrrZ6L+g9l1TETWT5qEm8NOJTxp0nKk4XJ0vkTpbpfdJF7/+gjdxOI5qST4KCDEjd8iO1luW6d93qxy6ur/ZN5ovEbe02Nm07wS6gyDCOchMciP/tsN/P4qU/x9tjJPH7N4/z5rpW8esnN7DxoFP0HSFqThcnS+ROluu/YAVOnZtfwob7eue0vu8y/PktNjf++29qci2bGDPceeZLwG3tVFdxyizVqMIxSJDxCPniwcya/9x6Pnn0HHx0+tkdXHb+aKn4kE+FIlIkf69al3/DBDy/h7dPHuVdOPRUmT4aFC7v3ncwtlKizjjVqMIzSIzxCDnDUUdC3byCtz1IR4WQid9RRLg78yithwQInxpnEgscKb02Ne//oI/f92rVwxx3Q0eH2Heub9/Kfm2AbRu8hECEXke+IiIpIbRD7S0YQlnDET11V5fzOfiIc696IJuKHXrsWZs92lnGmCT3RwltdHT/5uX073Hyz+zudKo+GYZQ+WU92isgewIlA3urUxU4WDhrkYq7TFdH6+sTbpJMoE2Td7mSVAFOt8mgYRu8gCIv8l8DV4NF9IYdETxZOmBB8anskqSY2ciSRhR4twImaNicjWd31oHzzhmGUBlkJuYiMB95V1RdTWPcyEWkVkdb2EPgAvBodgHNh+EWZRIQ2chNYscLlMEVqj6cq5n5RJ5EwwVTdQoZh9A6SZnaKyOPAEI+vpgHfB05U1Q0i8jYwSlU9ktR7ktOiWQHhV2RKBGbNSpy+n0pWaDKam3PfFs4wjHAReIq+iBwA/BmIyFk9sAo4TFXfS7RtGIQ8mRgnEtpENwFLhTcMI1MCT9FX1ZdUdbCqjlTVkUAbcEgyEQ8LydwbicL7kvm4DcMwgiRcceR5JFFSjRfRk5ubN7ta49FYKrxhGLkiXNUPixS/srG77eb6XJiP2zCMIPBzrYSnaFYR4xXhsn27i3Dxqk9uGIYRJOZaCYBkCTy5IJs4dcMwSgsT8gDI9+RmtnHqhmGUFibkAZAswiVovFw5kRIBhmH0PkIv5MXgYkg3wiVbCuHKMQyjeAn1ZGdstEjExQD5jxCJ1PrOB34dgCxO3TB6J6G2yMPgYkjUySdT8u3KMQyjuAm1kCdyMRSDyyVZJ59MybcrxzCM4ibUCUF+9VD8mgzPmOHqli9Z4powDBrkSr/mqmrgvHluDNF1wzdudGOZMCE3xzQMo3QJvNZKMeDnYgBvl8vVV+fGQvbDOvkYhpEPQi3kfi6G9eu911+1KnmvyyAJoreoYRhGMkIt5OBdhdAvemPgwPxayNbJxzCMfBB6IffCz+Vy/vn5tZC9Ovkcdph7AggyisUwjN5NqOPI/YhEb8Q2fhgzxvnEwVnimzc7C3nMmNyNJbrBcySKpX9/56PfvNl9tjZthmFkQ6ijVjKhrS1/USuxWBSLYRjZYGVsu4i2kPNNe7uzxKOprnZuF8MwjEwpSR95sWJRLIZh5ILQC3kxZHCmikWxGIaRC0It5GGry+0VxWITnYZhZEuoJzv9UvQbGlxMuWEYRilRkin6VpfbMAwj5EKe7xZrhmEYxUiohdzqchuGYYRcyK0ut2EYRgkkBOWzxZphGEYxEmqL3DAMwzAhNwzDCD0m5IZhGCEnayEXkW+KyGsi8oqI3BjEoAzDMIzUyWqyU0SOA8YDB6rqNhEZHMywDMMwjFTJ1iKfAtygqtsAVPX97IdkGIZhpEO2Qv5vwNEi8oyIPCkivnX8ROQyEWkVkdZ2ayNvGIYRGEldKyLyODDE46tpXdsPBA4HRgN/EJG91KMSl6rOAGaAK5qVzaANwzCMbpIKuap+0e87EZkCzO0S7mdFpBOoBczkNgzDyBPZulYeAI4DEJF/AyqBtVnu0zAMw0iDbFP07wTuFJGXge3ABV5uFcMwDCN3ZGWRq+p2VT1PVfdX1UNU9YmgBpYqYWr1ZhiGkQtCXTQr0uptyxb3OdLqDayQlmEYvYdQp+hPm9Yt4hG2bHHLDcMweguhFnJr9WYYhhFyIbdWb4ZhGCEXcmv1ZhiGEXIht1ZvhmEYIY9aAWv1ZhiGEWqL3DAMwzAhNwzDCD0m5IZhGCHHhNwwDCPkmJAbhmGEHClEsUIRaQdWZLh5LcVZKtfGlR7FOi4o3rHZuNKjFMfVoKqDYhcWRMizQURaVXVUoccRi40rPYp1XFC8Y7NxpUdvGpe5VgzDMEKOCblhGEbICaOQzyj0AHywcaVHsY4LindsNq706DXjCp2P3DAMw+hJGC1ywzAMIwoTcsMwjJBT9EIuIjeJyGsislRE5olIf5/1viQi/xSRN0TkmjyM6ywReUVEOkXEN5RIRN4WkZdE5AURaS2iceX7eg0UkcdEZHnX+wCf9Tq6rtULIrIgh+NJeP4isouI3Nv1/TMiMjJXY0lzXBeKSHvUNbokT+O6U0TeF5GXfb4XEflV17iXisghRTKuY0VkQ9T1+q88jWsPEVkkIsu6/j9O9VgnuGumqkX9Ak4E+nT9/TPgZx7rlANvAnsBlcCLwGdzPK79gH2BxcCoBOu9DdTm8XolHVeBrteNwDVdf1/j9e/Y9d3mPFyjpOcPXAH8ruvvicC9RTKuC4Hp+fo9RR33GOAQ4GWf78cBCwEBDgeeKZJxHQs8VIDrNRQ4pOvv3YDXPf4tA7tmRW+Rq+qjqrqz6+PTQL3HaocBb6jqW6q6HZgNjM/xuF5V1X/m8hiZkOK48n69uvY/s+vvmcBpOT5eIlI5/+jx3g+MFREpgnEVBFX9C7A+wSrjgbvV8TTQX0SGFsG4CoKqrlbV57v+3gS8CgyPWS2wa1b0Qh7DZNwdLJbhwMqoz23EX7RCocCjIvKciFxW6MF0UYjrVaeqq7v+fg+o81mvr4i0isjTInJajsaSyvl/sk6XIbEBqMnReNIZF8AZXY/i94vIHjkeU6oU8//BI0TkRRFZKCKfy/fBu9xyBwPPxHwV2DUrig5BIvI4MMTjq2mqOr9rnWnATqC5mMaVAkep6rsiMhh4TERe67IiCj2uwEk0rugPqqoi4hf32tB1vfYCnhCRl1T1zaDHGmIeBO5R1W0i8jXcU8PxBR5TMfM87je1WUTGAQ8An87XwUWkGpgDXKmqG3N1nKIQclX9YqLvReRC4BRgrHY5l2J4F4i2TOq7luV0XCnu492u9/dFZB7u8TkrIQ9gXHm/XiKyRkSGqurqrsfH9332Ebleb4nIYpwlE7SQp3L+kXXaRKQP8ClgXcDjSHtcqho9httxcw/FQE5+U9kSLZ6q+oiI/EZEalU158W0RKQCJ+LNqjrXY5XArlnRu1ZE5EvA1cCpqrrFZ7UlwKdFZE8RqcRNTuUs4iFVRGRXEdkt8jdu4tZzdj3PFOJ6LQAu6Pr7AiDuyUFEBojILl1/1wJfAJblYCypnH/0eM8EnvAxIvI6rhgf6qk432sxsAD4alckxuHAhihXWsEQkSGRuQ0ROQynebm+IdN1zDuAV1X1Zp/Vgrtm+Z7NzWD29w2cH+mFrlckkmAY8EjMDPDrOOttWh7GNQHn09oGrAH+FDsuXPTBi12vV4plXAW6XjXAn4HlwOPAwK7lo4Dbu/4+Enip63q9BFycw/HEnT/wY5zBANAXuK/r9/cssFeur1GK4/pp12/pRWAR8Jk8jeseYDWwo+v3dTFwOXB51/cC3No17pdIEMmV53F9I+p6PQ0cmadxHYWbH1sapV3jcnXNLEXfMAwj5BS9a8UwDMNIjAm5YRhGyDEhNwzDCDkm5IZhGCHHhNwwDCPkmJAbhmGEHBNywzCMkPP/ARoVb4eP/bz6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#학습한 선형 모델 시각화\n",
    "x_arr = np.arange(-2,2,0.1)\n",
    "y_arr = model.predict(x_arr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_train,y_train,'bo')#훈련 세트\n",
    "plt.plot(x_test,y_test,'bo',alpha=0.3)#테스트 세트\n",
    "plt.plot(x_arr, y_arr, '-r',lw = 3)#선형 모델\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d98081",
   "metadata": {},
   "source": [
    "### 계산 그래프 시각화\n",
    "\n",
    "<b>텐서보드(TensorBoard): 모델의 학습 과정뿐만 아니라 계산 그래프도 시각화할 수 있는 모듈</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "82f9e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 1, input_dim = 1, kernel_regularizer = 'l2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "dcc84642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 13s 192ms/step - loss: 11.1861 - val_loss: 6.3621\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.2849 - val_loss: 5.1231\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.8249 - val_loss: 4.3692\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9158 - val_loss: 3.7123\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.9831 - val_loss: 3.1436\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.0813 - val_loss: 2.7225\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.2166 - val_loss: 2.4041\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.9101 - val_loss: 2.1609\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.4780 - val_loss: 1.9058\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.2586 - val_loss: 1.7314\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.9540 - val_loss: 1.5676\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.5847 - val_loss: 1.4380\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.3769 - val_loss: 1.3310\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.2532 - val_loss: 1.2558\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1994 - val_loss: 1.1924\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2770 - val_loss: 1.1487\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0345 - val_loss: 1.1072\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0072 - val_loss: 1.0771\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9610 - val_loss: 1.0532\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8730 - val_loss: 1.0240\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9188 - val_loss: 1.0090\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8150 - val_loss: 0.9930\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8747 - val_loss: 0.9794\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9742 - val_loss: 0.9727\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8852 - val_loss: 0.9610\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7580 - val_loss: 0.9577\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8422 - val_loss: 0.9518\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7774 - val_loss: 0.9486\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8209 - val_loss: 0.9495\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7403 - val_loss: 0.9446\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8952 - val_loss: 0.9424\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9007 - val_loss: 0.9415\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7834 - val_loss: 0.9382\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8325 - val_loss: 0.9374\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7692 - val_loss: 0.9312\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7435 - val_loss: 0.9317\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7346 - val_loss: 0.9328\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7873 - val_loss: 0.9340\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7717 - val_loss: 0.9336\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7473 - val_loss: 0.9338\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8374 - val_loss: 0.9325\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8133 - val_loss: 0.9307\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8883 - val_loss: 0.9278\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6664 - val_loss: 0.9230\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7631 - val_loss: 0.9302\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7616 - val_loss: 0.9318\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7692 - val_loss: 0.9309\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8125 - val_loss: 0.9288\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7803 - val_loss: 0.9301\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7703 - val_loss: 0.9359\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8432 - val_loss: 0.9320\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8341 - val_loss: 0.9311\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8164 - val_loss: 0.9288\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8714 - val_loss: 0.9262\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7384 - val_loss: 0.9278\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6638 - val_loss: 0.9225\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7906 - val_loss: 0.9268\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7740 - val_loss: 0.9300\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7543 - val_loss: 0.9283\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7703 - val_loss: 0.9294\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8425 - val_loss: 0.9302\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8491 - val_loss: 0.9347\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7334 - val_loss: 0.9349\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7536 - val_loss: 0.9381\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7177 - val_loss: 0.9372\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7765 - val_loss: 0.9409\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7703 - val_loss: 0.9361\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7268 - val_loss: 0.9339\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7617 - val_loss: 0.9397\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7711 - val_loss: 0.9371\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7385 - val_loss: 0.9363\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7139 - val_loss: 0.9332\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8078 - val_loss: 0.9323\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7343 - val_loss: 0.9340\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6948 - val_loss: 0.9316\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8530 - val_loss: 0.9303\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7753 - val_loss: 0.9277\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7655 - val_loss: 0.9257\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7099 - val_loss: 0.9300\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7587 - val_loss: 0.9269\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8622 - val_loss: 0.9256\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8457 - val_loss: 0.9288\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8387 - val_loss: 0.9271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6835 - val_loss: 0.9341\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7310 - val_loss: 0.9301\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7723 - val_loss: 0.9341\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7180 - val_loss: 0.9369\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8238 - val_loss: 0.9349\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8379 - val_loss: 0.9361\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9631 - val_loss: 0.9372\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7078 - val_loss: 0.9387\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7747 - val_loss: 0.9357\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7745 - val_loss: 0.9373\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7502 - val_loss: 0.9411\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7389 - val_loss: 0.9376\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7949 - val_loss: 0.9342\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8410 - val_loss: 0.9377\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7720 - val_loss: 0.9375\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8276 - val_loss: 0.9366\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7881 - val_loss: 0.9343\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8065 - val_loss: 0.9327\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7612 - val_loss: 0.9297\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8114 - val_loss: 0.9279\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6870 - val_loss: 0.9257\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8559 - val_loss: 0.9284\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8421 - val_loss: 0.9286\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8136 - val_loss: 0.9340\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8081 - val_loss: 0.9323\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7711 - val_loss: 0.9346\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8015 - val_loss: 0.9344\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7594 - val_loss: 0.9345\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7343 - val_loss: 0.9373\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7337 - val_loss: 0.9366\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8103 - val_loss: 0.9337\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7790 - val_loss: 0.9284\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7204 - val_loss: 0.9258\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8055 - val_loss: 0.9267\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8575 - val_loss: 0.9285\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8330 - val_loss: 0.9287\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7894 - val_loss: 0.9301\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7949 - val_loss: 0.9341\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8430 - val_loss: 0.9328\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8656 - val_loss: 0.9340\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8287 - val_loss: 0.9365\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7591 - val_loss: 0.9331\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7199 - val_loss: 0.9314\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8151 - val_loss: 0.9314\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6749 - val_loss: 0.9365\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7828 - val_loss: 0.9332\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8208 - val_loss: 0.9328\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6925 - val_loss: 0.9363\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7401 - val_loss: 0.9380\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7352 - val_loss: 0.9326\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7488 - val_loss: 0.9359\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7691 - val_loss: 0.9315\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8767 - val_loss: 0.9311\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7460 - val_loss: 0.9372\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8578 - val_loss: 0.9363\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7857 - val_loss: 0.9341\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7800 - val_loss: 0.9339\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7947 - val_loss: 0.9313\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8555 - val_loss: 0.9310\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7555 - val_loss: 0.9361\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7619 - val_loss: 0.9358\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7486 - val_loss: 0.9315\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7190 - val_loss: 0.9293\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7283 - val_loss: 0.9292\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8299 - val_loss: 0.9317\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7100 - val_loss: 0.9276\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7238 - val_loss: 0.9268\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7073 - val_loss: 0.9316\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8809 - val_loss: 0.9342\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7088 - val_loss: 0.9357\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7804 - val_loss: 0.9340\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9053 - val_loss: 0.9339\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8452 - val_loss: 0.9370\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7762 - val_loss: 0.9357\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7085 - val_loss: 0.9370\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7231 - val_loss: 0.9317\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7947 - val_loss: 0.9319\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8233 - val_loss: 0.9314\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7607 - val_loss: 0.9289\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8667 - val_loss: 0.9300\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6682 - val_loss: 0.9305\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7043 - val_loss: 0.9386\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8682 - val_loss: 0.9389\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8110 - val_loss: 0.9371\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7854 - val_loss: 0.9409\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7947 - val_loss: 0.9401\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6984 - val_loss: 0.9358\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7432 - val_loss: 0.9391\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6796 - val_loss: 0.9401\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7610 - val_loss: 0.9407\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8396 - val_loss: 0.9400\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7932 - val_loss: 0.9396\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7385 - val_loss: 0.9394\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8087 - val_loss: 0.9433\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7642 - val_loss: 0.9421\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7031 - val_loss: 0.9407\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7747 - val_loss: 0.9370\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7705 - val_loss: 0.9373\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7664 - val_loss: 0.9471\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7388 - val_loss: 0.9408\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7824 - val_loss: 0.9408\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7310 - val_loss: 0.9472\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7936 - val_loss: 0.9466\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8508 - val_loss: 0.9445\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8048 - val_loss: 0.9470\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7714 - val_loss: 0.9426\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7456 - val_loss: 0.9418\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8517 - val_loss: 0.9430\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7132 - val_loss: 0.9416\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7630 - val_loss: 0.9412\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8033 - val_loss: 0.9403\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7906 - val_loss: 0.9367\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7244 - val_loss: 0.9358\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7777 - val_loss: 0.9371\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7734 - val_loss: 0.9339\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7307 - val_loss: 0.9354\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7786 - val_loss: 0.9312\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7694 - val_loss: 0.9297\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6861 - val_loss: 0.9295\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7792 - val_loss: 0.9287\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7157 - val_loss: 0.9336\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8258 - val_loss: 0.9324\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7974 - val_loss: 0.9311\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7506 - val_loss: 0.9385\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8313 - val_loss: 0.9397\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7991 - val_loss: 0.9363\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7745 - val_loss: 0.9375\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7125 - val_loss: 0.9344\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9028 - val_loss: 0.9332\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8680 - val_loss: 0.9346\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7379 - val_loss: 0.9311\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7415 - val_loss: 0.9328\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7446 - val_loss: 0.9382\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8123 - val_loss: 0.9334\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7314 - val_loss: 0.9306\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8704 - val_loss: 0.9297\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8042 - val_loss: 0.9325\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7505 - val_loss: 0.9321\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7422 - val_loss: 0.9341\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7994 - val_loss: 0.9340\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7327 - val_loss: 0.9366\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7427 - val_loss: 0.9364\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7818 - val_loss: 0.9350\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7439 - val_loss: 0.9316\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7817 - val_loss: 0.9285\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7196 - val_loss: 0.9279\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7791 - val_loss: 0.9297\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7908 - val_loss: 0.9253\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7956 - val_loss: 0.9295\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6443 - val_loss: 0.9262\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8381 - val_loss: 0.9238\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7797 - val_loss: 0.9244\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8909 - val_loss: 0.9241\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8264 - val_loss: 0.9232\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7183 - val_loss: 0.9245\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8195 - val_loss: 0.9256\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7537 - val_loss: 0.9280\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7421 - val_loss: 0.9316\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8585 - val_loss: 0.9308\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7768 - val_loss: 0.9280\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7738 - val_loss: 0.9291\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7901 - val_loss: 0.9311\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7012 - val_loss: 0.9331\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8726 - val_loss: 0.9344\n",
      "Epoch 248/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7303 - val_loss: 0.9313\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8016 - val_loss: 0.9295\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7850 - val_loss: 0.9304\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7719 - val_loss: 0.9311\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8510 - val_loss: 0.9297\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8119 - val_loss: 0.9347\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7810 - val_loss: 0.9330\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8331 - val_loss: 0.9362\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8452 - val_loss: 0.9359\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8199 - val_loss: 0.9332\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8031 - val_loss: 0.9304\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7407 - val_loss: 0.9308\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6882 - val_loss: 0.9367\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7031 - val_loss: 0.9389\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7687 - val_loss: 0.9395\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7781 - val_loss: 0.9417\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8291 - val_loss: 0.9384\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7673 - val_loss: 0.9395\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7894 - val_loss: 0.9388\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8978 - val_loss: 0.9397\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7802 - val_loss: 0.9413\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8253 - val_loss: 0.9432\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8078 - val_loss: 0.9496\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7091 - val_loss: 0.9514\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8212 - val_loss: 0.9498\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8207 - val_loss: 0.9539\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7495 - val_loss: 0.9524\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7506 - val_loss: 0.9518\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8170 - val_loss: 0.9520\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6947 - val_loss: 0.9525\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8163 - val_loss: 0.9503\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6966 - val_loss: 0.9435\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6906 - val_loss: 0.9383\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8084 - val_loss: 0.9368\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8137 - val_loss: 0.9383\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7798 - val_loss: 0.9411\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8022 - val_loss: 0.9404\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7984 - val_loss: 0.9373\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.923 - 0s 11ms/step - loss: 0.8355 - val_loss: 0.9365\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8237 - val_loss: 0.9327\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7780 - val_loss: 0.9285\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8404 - val_loss: 0.9272\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8349 - val_loss: 0.9291\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8169 - val_loss: 0.9275\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7514 - val_loss: 0.9300\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7351 - val_loss: 0.9274\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7541 - val_loss: 0.9248\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8178 - val_loss: 0.9228\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8104 - val_loss: 0.9308\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7886 - val_loss: 0.9354\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7421 - val_loss: 0.9332\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8495 - val_loss: 0.9328\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8233 - val_loss: 0.9321\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7747 - val_loss: 0.9345\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8185 - val_loss: 0.9334\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7777 - val_loss: 0.9359\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8384 - val_loss: 0.9310\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8476 - val_loss: 0.9300\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8315 - val_loss: 0.9302\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7615 - val_loss: 0.9288\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7549 - val_loss: 0.9271\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7343 - val_loss: 0.9295\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8565 - val_loss: 0.9289\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7487 - val_loss: 0.9271\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7763 - val_loss: 0.9273\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6902 - val_loss: 0.9269\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7444 - val_loss: 0.9301\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7217 - val_loss: 0.9268\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7525 - val_loss: 0.9304\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7020 - val_loss: 0.9288\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7701 - val_loss: 0.9254\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8175 - val_loss: 0.9279\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8349 - val_loss: 0.9264\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8463 - val_loss: 0.9231\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7911 - val_loss: 0.9220\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8122 - val_loss: 0.9276\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7606 - val_loss: 0.9266\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7377 - val_loss: 0.9288\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8131 - val_loss: 0.9294\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7684 - val_loss: 0.9308\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8429 - val_loss: 0.9294\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7732 - val_loss: 0.9307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8349 - val_loss: 0.9273\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7955 - val_loss: 0.9295\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8046 - val_loss: 0.9262\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7699 - val_loss: 0.9278\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8635 - val_loss: 0.9293\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8090 - val_loss: 0.9354\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7334 - val_loss: 0.9368\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7445 - val_loss: 0.9392\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7981 - val_loss: 0.9345\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8299 - val_loss: 0.9354\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7573 - val_loss: 0.9298\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7260 - val_loss: 0.9362\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7723 - val_loss: 0.9358\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7446 - val_loss: 0.9342\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7739 - val_loss: 0.9362\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7987 - val_loss: 0.9369\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8236 - val_loss: 0.9392\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7367 - val_loss: 0.9399\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7386 - val_loss: 0.9410\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8081 - val_loss: 0.9404\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8786 - val_loss: 0.9406\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8063 - val_loss: 0.9409\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8103 - val_loss: 0.9377\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7841 - val_loss: 0.9390\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8154 - val_loss: 0.9357\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7734 - val_loss: 0.9368\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6666 - val_loss: 0.9385\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8050 - val_loss: 0.9370\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7907 - val_loss: 0.9394\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7415 - val_loss: 0.9398\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7582 - val_loss: 0.9393\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7301 - val_loss: 0.9375\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7381 - val_loss: 0.9446\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7818 - val_loss: 0.9451\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6897 - val_loss: 0.9390\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7903 - val_loss: 0.9392\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8634 - val_loss: 0.9360\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9382 - val_loss: 0.9356\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8003 - val_loss: 0.9352\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7045 - val_loss: 0.9351\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7654 - val_loss: 0.9321\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7050 - val_loss: 0.9320\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8679 - val_loss: 0.9311\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7933 - val_loss: 0.9320\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8439 - val_loss: 0.9317\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8787 - val_loss: 0.9314\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7916 - val_loss: 0.9342\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7353 - val_loss: 0.9363\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8204 - val_loss: 0.9326\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8357 - val_loss: 0.9388\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7980 - val_loss: 0.9372\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7791 - val_loss: 0.9392\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8001 - val_loss: 0.9391\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7697 - val_loss: 0.9313\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8111 - val_loss: 0.9311\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7798 - val_loss: 0.9282\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8174 - val_loss: 0.9306\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7998 - val_loss: 0.9307\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7858 - val_loss: 0.9323\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8403 - val_loss: 0.9318\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7293 - val_loss: 0.9318\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7684 - val_loss: 0.9307\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7980 - val_loss: 0.9292\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7974 - val_loss: 0.9307\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7543 - val_loss: 0.9335\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6818 - val_loss: 0.9299\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7213 - val_loss: 0.9257\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7803 - val_loss: 0.9296\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7418 - val_loss: 0.9297\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6698 - val_loss: 0.9293\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7185 - val_loss: 0.9340\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8041 - val_loss: 0.9336\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8332 - val_loss: 0.9376\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7637 - val_loss: 0.9370\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8525 - val_loss: 0.9350\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8486 - val_loss: 0.9379\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7119 - val_loss: 0.9337\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7280 - val_loss: 0.9334\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7593 - val_loss: 0.9339\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8301 - val_loss: 0.9338\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7304 - val_loss: 0.9332\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8319 - val_loss: 0.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7156 - val_loss: 0.9263\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7669 - val_loss: 0.9250\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6778 - val_loss: 0.9243\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8000 - val_loss: 0.9240\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8468 - val_loss: 0.9241\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6788 - val_loss: 0.9333\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7707 - val_loss: 0.9345\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7609 - val_loss: 0.9428\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7638 - val_loss: 0.9448\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7697 - val_loss: 0.9404\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7450 - val_loss: 0.9450\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8067 - val_loss: 0.9421\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6796 - val_loss: 0.9417\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8351 - val_loss: 0.9395\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8463 - val_loss: 0.9370\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7806 - val_loss: 0.9364\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8205 - val_loss: 0.9372\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7644 - val_loss: 0.9390\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7380 - val_loss: 0.9378\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7218 - val_loss: 0.9335\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7631 - val_loss: 0.9325\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8481 - val_loss: 0.9297\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7190 - val_loss: 0.9307\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6839 - val_loss: 0.9324\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7539 - val_loss: 0.9374\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8319 - val_loss: 0.9353\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7425 - val_loss: 0.9372\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7589 - val_loss: 0.9367\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7522 - val_loss: 0.9397\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7207 - val_loss: 0.9386\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7852 - val_loss: 0.9331\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7040 - val_loss: 0.9361\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7737 - val_loss: 0.9384\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7660 - val_loss: 0.9382\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7585 - val_loss: 0.9364\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7869 - val_loss: 0.9313\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8001 - val_loss: 0.9327\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8634 - val_loss: 0.9324\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7405 - val_loss: 0.9299\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8887 - val_loss: 0.9291\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7757 - val_loss: 0.9280\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6772 - val_loss: 0.9284\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8868 - val_loss: 0.9267\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8120 - val_loss: 0.9266\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7502 - val_loss: 0.9252\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7105 - val_loss: 0.9243\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7375 - val_loss: 0.9225\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8144 - val_loss: 0.9237\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7599 - val_loss: 0.9281\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8007 - val_loss: 0.9281\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7560 - val_loss: 0.9304\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7461 - val_loss: 0.9288\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8376 - val_loss: 0.9289\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8005 - val_loss: 0.9274\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7900 - val_loss: 0.9285\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8223 - val_loss: 0.9271\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7171 - val_loss: 0.9331\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7753 - val_loss: 0.9334\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7564 - val_loss: 0.9294\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7854 - val_loss: 0.9309\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7253 - val_loss: 0.9328\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7977 - val_loss: 0.9285\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8606 - val_loss: 0.9303\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7609 - val_loss: 0.9354\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7997 - val_loss: 0.9374\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6970 - val_loss: 0.9339\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8132 - val_loss: 0.9344\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6582 - val_loss: 0.9333\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6988 - val_loss: 0.9331\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8231 - val_loss: 0.9287\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7448 - val_loss: 0.9270\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7613 - val_loss: 0.9271\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8412 - val_loss: 0.9282\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8740 - val_loss: 0.9297\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7381 - val_loss: 0.9344\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8554 - val_loss: 0.9353\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9740 - val_loss: 0.9344\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7011 - val_loss: 0.9348\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8129 - val_loss: 0.9360\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7197 - val_loss: 0.9346\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8112 - val_loss: 0.9334\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8060 - val_loss: 0.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7571 - val_loss: 0.9331\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7210 - val_loss: 0.9304\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7557 - val_loss: 0.9276\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7559 - val_loss: 0.9291\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7652 - val_loss: 0.9311\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7092 - val_loss: 0.9340\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7520 - val_loss: 0.9334\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard#텐서보드 임포트\n",
    "callback_list = [TensorBoard()]\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train,y_train, epochs=500, callbacks=callback_list, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7165425b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b1bd81b5819365e6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b1bd81b5819365e6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#주피터에서 텐서보드 포함시키기\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs --port 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd209f",
   "metadata": {},
   "source": [
    "### 케라스의 층 그래프 그리기 plot_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0ed115e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.Input(shape = (784,))\n",
    "hidden = tf.keras.layers.Dense(100)(input)\n",
    "output = tf.keras.layers.Dense(10)(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "502a5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(input,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fb9bff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "#plot_model: 케라스의 층 그래프 그리기\n",
    "tf.keras.utils.plot_model(model,to_file='model_1.png')#파일에 그래프 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4745f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\anaconda3\\envs\\dsfs\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\anaconda3\\envs\\dsfs\\lib\\site-packages (from pydot) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6d929def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\anaconda3\\envs\\dsfs\\lib\\site-packages (0.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1aa0317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "#show_shapes = True: 층 입력과 출력 크기를 함께 나타내기\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, to_file = 'model_2.png')#외않되"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
